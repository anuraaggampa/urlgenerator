{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc07208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Super-7 Vertex AI Extractor (Final Merged Version)\n",
    "\n",
    "- Uses Vertex AI Gemini with Google Search grounding\n",
    "- Extracts Super-7 fields + metadata for each company\n",
    "- 3-attempt retry engine with different search strategies\n",
    "- Early stop when confidence is high\n",
    "- LLM-powered dynamic URL classification (gov/registry/official/directory/etc.)\n",
    "- LLM-generated url_metadata and field_metadata with trust_assessment\n",
    "- Second-pass enhanced search using high-confidence fields\n",
    "- Scoring uses: base_confidence Ã— source_type_weight Ã— url_quality Ã— trust_assessment\n",
    "- process_company_row(...) for single company\n",
    "- process_csv_print_only(...) for CSV batch (prints JSON for debugging)\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "# ==================== CONFIG ====================\n",
    "\n",
    "PROJECT_ID = \"YOUR_GCP_PROJECT_ID\"  # <-- change this\n",
    "LOCATION = \"us-east4\"\n",
    "MODEL_NAME = \"gemini-2.0-flash\"\n",
    "\n",
    "MAX_RETRIES = 3\n",
    "EARLY_STOP_THRESHOLD = 0.92  # early-stop if overall score >= this\n",
    "\n",
    "# Expected CSV columns (you can have more; these are the ones we use)\n",
    "DEFAULT_INPUT_COLS = [\n",
    "    \"company_name\",\n",
    "    \"country\",\n",
    "    \"state_province\",\n",
    "    \"city\",\n",
    "    \"street_address\",\n",
    "    \"postal_code\",\n",
    "    \"phone_number\",\n",
    "    \"additional_info\",\n",
    "]\n",
    "\n",
    "# Super-7-style fields we score\n",
    "SUPER7_FIELDS = [\n",
    "    \"company_name\",\n",
    "    \"trade_style_name\",\n",
    "    \"country\",\n",
    "    \"street_address\",\n",
    "    \"postal_code\",\n",
    "    \"city\",\n",
    "    \"state_province\",\n",
    "    \"website\",\n",
    "    \"phone_number\",\n",
    "]\n",
    "\n",
    "# Source-type weights for scoring\n",
    "SOURCE_TYPE_WEIGHTS = {\n",
    "    \"government_registry\": 1.0,\n",
    "    \"official_website\": 0.9,\n",
    "    \"business_directory\": 0.75,\n",
    "    \"social_media\": 0.7,\n",
    "    \"high_quality_industry_source\": 0.75,\n",
    "    \"other\": 0.6,\n",
    "}\n",
    "\n",
    "# TLD-based heuristics for URL quality\n",
    "TLD_WEIGHTS = {\n",
    "    \".gov\": 1.0,\n",
    "    \".gov.in\": 1.0,\n",
    "    \".gov.uk\": 1.0,\n",
    "    \".edu\": 0.9,\n",
    "    \".com\": 0.85,\n",
    "    \".org\": 0.82,\n",
    "    \".net\": 0.8,\n",
    "    \".co\": 0.78,\n",
    "    \".io\": 0.75,\n",
    "}\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AttemptResult:\n",
    "    attempt_index: int\n",
    "    strategy_name: str\n",
    "    raw_object: Dict[str, Any]\n",
    "    overall_score: float\n",
    "\n",
    "\n",
    "# ==================== CLIENT ====================\n",
    "\n",
    "def init_gemini_client() -> genai.Client:\n",
    "    \"\"\"\n",
    "    Initialize Gemini client with Vertex AI.\n",
    "    Make sure you have configured ADC (gcloud auth application-default login).\n",
    "    \"\"\"\n",
    "    return genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "\n",
    "# ==================== STRING / NAME VARIANT HELPERS ====================\n",
    "\n",
    "CORP_SUFFIXES = [\n",
    "    \"inc\", \"inc.\", \"llc\", \"l.l.c\", \"corp\", \"corp.\", \"corporation\",\n",
    "    \"ltd\", \"ltd.\", \"limited\", \"pvt\", \"pvt.\", \"pvt ltd\", \"pty\", \"pty ltd\",\n",
    "    \"gmbh\", \"ag\", \"sa\", \"s.a.\", \"bv\", \"srl\", \"s.r.l.\",\n",
    "]\n",
    "\n",
    "\n",
    "def normalize_whitespace(s: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "\n",
    "def strip_corp_suffix(name: str) -> str:\n",
    "    tokens = name.split()\n",
    "    lowered = [t.lower().strip(\",.\") for t in tokens]\n",
    "    end = len(tokens)\n",
    "    while end > 0 and lowered[end - 1] in CORP_SUFFIXES:\n",
    "        end -= 1\n",
    "    return normalize_whitespace(\" \".join(tokens[:end]))\n",
    "\n",
    "\n",
    "def generate_name_variants(company_name: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate multiple useful variants of the company name for search.\n",
    "    Ensures all variants still contain the core token of the name.\n",
    "    \"\"\"\n",
    "    if not company_name:\n",
    "        return []\n",
    "\n",
    "    base = normalize_whitespace(company_name)\n",
    "    no_suffix = strip_corp_suffix(base)\n",
    "\n",
    "    variants = set()\n",
    "    variants.add(base)\n",
    "    variants.add(no_suffix)\n",
    "\n",
    "    tokens = no_suffix.split()\n",
    "    if not tokens:\n",
    "        return [base]\n",
    "\n",
    "    # core token\n",
    "    core = tokens[0]\n",
    "\n",
    "    if len(tokens) >= 2:\n",
    "        variants.add(\" \".join(tokens[:2]))\n",
    "    if len(tokens) >= 3:\n",
    "        variants.add(\" \".join(tokens[:3]))\n",
    "\n",
    "    variants.add(core)\n",
    "    variants.add(f\"{core} llc\")\n",
    "    variants.add(f\"{core} ltd\")\n",
    "    variants.add(f\"{core} corp\")\n",
    "\n",
    "    cleaned = []\n",
    "    seen = set()\n",
    "    for v in variants:\n",
    "        v2 = normalize_whitespace(v)\n",
    "        low = v2.lower()\n",
    "        if v2 and low not in seen:\n",
    "            cleaned.append(v2)\n",
    "            seen.add(low)\n",
    "\n",
    "    # limit to keep prompt compact\n",
    "    return cleaned[:12]\n",
    "\n",
    "\n",
    "# ==================== CONTEXT & STRATEGIES ====================\n",
    "\n",
    "def build_company_context(row_dict: Dict[str, Any]) -> str:\n",
    "    \"\"\"\n",
    "    Build a small context block using CSV fields.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for col in DEFAULT_INPUT_COLS:\n",
    "        v = row_dict.get(col)\n",
    "        if v is not None and str(v).strip():\n",
    "            lines.append(f\"{col}: {v}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def build_search_strategies(\n",
    "    row_dict: Dict[str, Any],\n",
    "    variants: List[str],\n",
    ") -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Build different textual search strategies (used by the LLM).\n",
    "    \"\"\"\n",
    "    company_name = row_dict.get(\"company_name\", \"\")\n",
    "    country = row_dict.get(\"country\", \"\")\n",
    "    city = row_dict.get(\"city\", \"\")\n",
    "    state = row_dict.get(\"state_province\", \"\")\n",
    "    postal = row_dict.get(\"postal_code\", \"\")\n",
    "\n",
    "    variants_str = \", \".join(f'\"{v}\"' for v in variants)\n",
    "    base_hint = f'Input company name: \"{company_name}\"'\n",
    "\n",
    "    strategies: List[Tuple[str, str]] = []\n",
    "\n",
    "    # Strategy 1: Gov + official\n",
    "    s1 = f\"\"\"\n",
    "{base_hint}\n",
    "Use these query patterns heavily:\n",
    "- Full & near-full names + \"{country}\" and the location \"{city} {state} {postal}\".\n",
    "- Words like \"business registry\", \"official registry\", \"secretary of state\",\n",
    "  \"MCA\", \"ROC\", \"Companies House\", \"ASIC\" depending on country.\n",
    "\n",
    "Prefer:\n",
    "1) Government or official business registries.\n",
    "2) Official corporate websites.\n",
    "Use name variants: {variants_str}\n",
    "\"\"\"\n",
    "    strategies.append((\"gov_official_strategy\", s1.strip()))\n",
    "\n",
    "    # Strategy 2: Address-boosted disambiguation\n",
    "    s2 = f\"\"\"\n",
    "{base_hint}\n",
    "Use location as a strong filter to disambiguate companies with similar names:\n",
    "- Combine \"city\", \"state_province\", \"postal_code\", \"{country}\" with the name variants.\n",
    "- Focus on queries like: \"<variant>\" \"<city>\" \"<state>\" \"<postal>\" \"<country>\".\n",
    "Use variants: {variants_str}\n",
    "\"\"\"\n",
    "    strategies.append((\"address_geo_strategy\", s2.strip()))\n",
    "\n",
    "    # Strategy 3: Directory + social fallback\n",
    "    s3 = f\"\"\"\n",
    "{base_hint}\n",
    "If registry / official is unclear:\n",
    "- Search business directories such as LinkedIn, Bloomberg, Crunchbase,\n",
    "  D&B, Manta, Yelp, BBB, YellowPages, OpenCorporates, industry registries.\n",
    "- Also consider company pages on social media if structured business info exists.\n",
    "Use variants: {variants_str}\n",
    "\"\"\"\n",
    "    strategies.append((\"directory_fallback_strategy\", s3.strip()))\n",
    "\n",
    "    return strategies\n",
    "\n",
    "\n",
    "# ==================== PROMPTS ====================\n",
    "\n",
    "def build_super7_prompt(\n",
    "    row_dict: Dict[str, Any],\n",
    "    strategy_name: str,\n",
    "    strategy_text: str,\n",
    "    variants: List[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Main extraction prompt for a single attempt with a given strategy.\n",
    "    Includes instructions for dynamic URL classification & metadata.\n",
    "    \"\"\"\n",
    "    company_context = build_company_context(row_dict)\n",
    "    variants_str = \", \".join(f'\"{v}\"' for v in variants)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a highly reliable company-information extractor that uses the Google Search tool.\n",
    "Your task is to:\n",
    "1) Use the search strategy,\n",
    "2) Inspect all grounded URLs,\n",
    "3) Dynamically classify and score them,\n",
    "4) Extract Super-7 company fields with detailed metadata.\n",
    "\n",
    "########################\n",
    "# COMPANY CONTEXT INPUT\n",
    "########################\n",
    "{company_context}\n",
    "\n",
    "########################\n",
    "# NAME VARIANTS FOR SEARCH\n",
    "########################\n",
    "Use all these name variants in your searches.\n",
    "Every query MUST still contain the core token from the original name:\n",
    "{variants_str}\n",
    "\n",
    "########################\n",
    "# SEARCH STRATEGY SELECTED ({strategy_name})\n",
    "########################\n",
    "{strategy_text}\n",
    "\n",
    "########################\n",
    "# URL CLASSIFICATION & METADATA\n",
    "########################\n",
    "For EVERY URL you observe via the Google Search tool:\n",
    "- Examine domain, path, snippet, page title, page content.\n",
    "- Dynamically classify source_type as one of:\n",
    "    \"government_registry\",\n",
    "    \"official_website\",\n",
    "    \"business_directory\",\n",
    "    \"social_media\",\n",
    "    \"high_quality_industry_source\",\n",
    "    \"other\"\n",
    "- Estimate trust_assessment (0.0 to 1.0).\n",
    "- Write a short comment justifying why this URL is classified that way\n",
    "  (e.g., \"official U.S. Secretary of State registry\", \"corporate about page\",\n",
    "  \"generic blog post with no structured company info\", etc.).\n",
    "\n",
    "The classification MUST NOT rely only on hard-coded domain lists:\n",
    "you must reason from the data, naming patterns, registry words, and actual content.\n",
    "\n",
    "########################\n",
    "# FIELDS TO EXTRACT (Super-7 + extra)\n",
    "########################\n",
    "Use the BEST subset of URLs to extract:\n",
    "\n",
    "- company_name          : official legal or main operating name\n",
    "- trade_style_name      : trading / doing-business-as name (if any)\n",
    "- country\n",
    "- street_address\n",
    "- postal_code\n",
    "- city\n",
    "- state_province\n",
    "- website               : full URL of official corporate site\n",
    "- phone_number          : primary business phone\n",
    "- line_of_business      : 1â€“3 sentence description of what the company does\n",
    "- reference_url         : up to 5 KEY URLs used in final extraction\n",
    "\n",
    "For EACH of these fields, provide:\n",
    "- source_url\n",
    "- source_type\n",
    "- trust_assessment (0.0â€“1.0)\n",
    "- comment  (short justification)\n",
    "\n",
    "########################\n",
    "# URL METADATA\n",
    "########################\n",
    "Also provide:\n",
    "\"url_metadata\": a list of ALL URLs you found relevant, with:\n",
    "    {{\n",
    "      \"url\": \"...\",\n",
    "      \"source_type\": \"...\",\n",
    "      \"trust_assessment\": 0.0,\n",
    "      \"comment\": \"...\"\n",
    "    }}\n",
    "\n",
    "########################\n",
    "# CONFIDENCE\n",
    "########################\n",
    "Provide:\n",
    "- base_model_confidence: 0.0â€“1.0 describing how confident you are in the overall object.\n",
    "\n",
    "########################\n",
    "# OUTPUT FORMAT (STRICT JSON)\n",
    "########################\n",
    "Return EXACTLY a single JSON array with ONE object:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"company_name\": \"...\",\n",
    "    \"trade_style_name\": \"...\",\n",
    "    \"country\": \"...\",\n",
    "    \"street_address\": \"...\",\n",
    "    \"postal_code\": \"...\",\n",
    "    \"city\": \"...\",\n",
    "    \"state_province\": \"...\",\n",
    "    \"website\": \"...\",\n",
    "    \"phone_number\": \"...\",\n",
    "    \"line_of_business\": \"...\",\n",
    "    \"reference_url\": [\"...\", \"...\"],\n",
    "    \"url_metadata\": [\n",
    "       {{\n",
    "          \"url\": \"...\",\n",
    "          \"source_type\": \"government_registry | official_website | business_directory | social_media | high_quality_industry_source | other\",\n",
    "          \"trust_assessment\": 0.0,\n",
    "          \"comment\": \"...\"\n",
    "       }}\n",
    "    ],\n",
    "    \"field_metadata\": {{\n",
    "      \"company_name\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"trade_style_name\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"country\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"street_address\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"postal_code\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"city\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"state_province\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"website\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }},\n",
    "      \"phone_number\": {{\n",
    "        \"source_url\": \"...\",\n",
    "        \"source_type\": \"...\",\n",
    "        \"trust_assessment\": 0.0,\n",
    "        \"comment\": \"...\"\n",
    "      }}\n",
    "    }},\n",
    "    \"base_model_confidence\": 0.0\n",
    "  }}\n",
    "]\n",
    "\n",
    "Rules:\n",
    "- JSON ONLY. No markdown, no extra commentary.\n",
    "- If a field is not found, set it to null but still provide metadata with \"not found\" comment.\n",
    "\"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "# ==================== MODEL CALLS ====================\n",
    "\n",
    "def clean_json_from_text(raw_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove markdown fences and stray text, try to isolate JSON.\n",
    "    \"\"\"\n",
    "    text = raw_text.strip()\n",
    "    text = re.sub(r\"^```json\", \"\", text, flags=re.IGNORECASE).strip()\n",
    "    text = re.sub(r\"^```\", \"\", text).strip()\n",
    "    if \"```\" in text:\n",
    "        text = text.split(\"```\", 1)[0].strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def call_gemini_with_grounding(\n",
    "    client: genai.Client,\n",
    "    prompt: str,\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Call Gemini with Google Search grounding and parse JSON.\n",
    "    \"\"\"\n",
    "    config = types.GenerateContentConfig(\n",
    "        temperature=0.0,\n",
    "        tools=[types.Tool(google_search=types.GoogleSearch())],\n",
    "    )\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=MODEL_NAME,\n",
    "            contents=prompt,\n",
    "            config=config,\n",
    "        )\n",
    "        raw_text = response.text or \"\"\n",
    "        cleaned = clean_json_from_text(raw_text)\n",
    "        data = json.loads(cleaned)\n",
    "        if isinstance(data, list) and data:\n",
    "            return data[0]\n",
    "        elif isinstance(data, dict):\n",
    "            return data\n",
    "        else:\n",
    "            print(\"âš  Unexpected JSON structure:\", type(data))\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"âš  Error in call_gemini_with_grounding:\", e)\n",
    "        return None\n",
    "\n",
    "\n",
    "# ==================== URL + FIELD SCORING ====================\n",
    "\n",
    "def extract_domain(url: Optional[str]) -> str:\n",
    "    if not url:\n",
    "        return \"\"\n",
    "    m = re.search(r\"https?://([^/]+)\", url)\n",
    "    return m.group(1).lower() if m else \"\"\n",
    "\n",
    "\n",
    "def url_quality(url: Optional[str]) -> float:\n",
    "    \"\"\"\n",
    "    Heuristic URL-quality score using TLD and https.\n",
    "    \"\"\"\n",
    "    if not url:\n",
    "        return 0.6\n",
    "    score = 0.7\n",
    "    domain = extract_domain(url)\n",
    "    for tld, w in TLD_WEIGHTS.items():\n",
    "        if domain.endswith(tld):\n",
    "            score = max(score, w)\n",
    "    if url.startswith(\"https://\"):\n",
    "        score += 0.05\n",
    "    return max(0.4, min(score, 1.0))\n",
    "\n",
    "\n",
    "def compute_field_score(field_name: str, obj: Dict[str, Any]) -> float:\n",
    "    \"\"\"\n",
    "    Compute score for a single field using:\n",
    "    - base_model_confidence\n",
    "    - LLM-provided source_type\n",
    "    - trust_assessment\n",
    "    - URL quality\n",
    "    \"\"\"\n",
    "    field_meta = (obj.get(\"field_metadata\") or {}).get(field_name) or {}\n",
    "    src_type = field_meta.get(\"source_type\", \"other\")\n",
    "    trust_assessment = float(field_meta.get(\"trust_assessment\") or 0.3)\n",
    "    src_url = field_meta.get(\"source_url\")\n",
    "\n",
    "    base_conf = float(obj.get(\"base_model_confidence\") or 0.0)\n",
    "    src_weight = SOURCE_TYPE_WEIGHTS.get(src_type, SOURCE_TYPE_WEIGHTS[\"other\"])\n",
    "    url_w = url_quality(src_url)\n",
    "\n",
    "    dynamic_factor = 0.5 + 0.5 * trust_assessment  # 0.5â€“1.0\n",
    "    score = base_conf * src_weight * url_w * dynamic_factor\n",
    "    return round(score, 4)\n",
    "\n",
    "\n",
    "def attach_scores(obj: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Attach per-field scores and an overall_confidence_score.\n",
    "    \"\"\"\n",
    "    field_scores: Dict[str, float] = {}\n",
    "    for f in SUPER7_FIELDS:\n",
    "        field_scores[f] = compute_field_score(f, obj)\n",
    "\n",
    "    if field_scores:\n",
    "        overall = sum(field_scores.values()) / len(field_scores)\n",
    "    else:\n",
    "        overall = 0.0\n",
    "\n",
    "    obj[\"field_scores\"] = field_scores\n",
    "    obj[\"overall_confidence_score\"] = round(overall, 4)\n",
    "    return obj\n",
    "\n",
    "\n",
    "# ==================== SECOND-PASS ENHANCED SEARCH ====================\n",
    "\n",
    "def run_second_pass_search(\n",
    "    client: genai.Client,\n",
    "    primary_obj: Dict[str, Any],\n",
    "    row_dict: Dict[str, Any],\n",
    "    variants: List[str],\n",
    ") -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    SECOND PASS:\n",
    "    If any Super-7 field has good confidence (>= 0.75),\n",
    "    build more precise queries combining the field value + company name,\n",
    "    then run a second call to refine and possibly improve the result.\n",
    "    \"\"\"\n",
    "    field_scores = primary_obj.get(\"field_scores\") or {}\n",
    "    high_conf_fields = [f for f, sc in field_scores.items() if sc >= 0.75]\n",
    "\n",
    "    if not high_conf_fields:\n",
    "        return None\n",
    "\n",
    "    cname = primary_obj.get(\"company_name\") or row_dict.get(\"company_name\", \"\")\n",
    "    queries = []\n",
    "    for f in high_conf_fields:\n",
    "        val = primary_obj.get(f)\n",
    "        if not val:\n",
    "            continue\n",
    "        v_str = normalize_whitespace(val)\n",
    "        queries.append(f'\"{cname}\" \"{v_str}\"')\n",
    "        queries.append(f'\"{cname}\" \"{v_str}\" address')\n",
    "        queries.append(f'\"{cname}\" \"{v_str}\" phone')\n",
    "        queries.append(f'\"{cname}\" \"{v_str}\" registered office')\n",
    "\n",
    "    if not queries:\n",
    "        return None\n",
    "\n",
    "    query_block = \"\\n\".join(f\"- {q}\" for q in queries)\n",
    "\n",
    "    second_pass_prompt = f\"\"\"\n",
    "You are performing a SECOND-PASS REFINEMENT for company information.\n",
    "\n",
    "We already have a provisional object with some high-confidence fields:\n",
    "{high_conf_fields}\n",
    "\n",
    "Use these refined queries as a strong hint to Google Search:\n",
    "{query_block}\n",
    "\n",
    "Task:\n",
    "1. Use Google Search tool with these refined queries.\n",
    "2. Re-check official website, address, and phone, and registry info.\n",
    "3. If you find more accurate or consistent info, update the fields accordingly.\n",
    "4. Return the SAME JSON STRUCTURE as before:\n",
    "   - Super-7 fields\n",
    "   - url_metadata\n",
    "   - field_metadata\n",
    "   - base_model_confidence\n",
    "5. Your goal is to IMPROVE or CONFIRM the original object.\n",
    "\n",
    "Return STRICT JSON with a single-element array as before.\n",
    "\"\"\"\n",
    "    obj = call_gemini_with_grounding(client, second_pass_prompt)\n",
    "    if not obj:\n",
    "        return None\n",
    "    obj = attach_scores(obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "# ==================== RETRY ENGINE ====================\n",
    "\n",
    "def run_single_attempt(\n",
    "    client: genai.Client,\n",
    "    attempt_index: int,\n",
    "    strategy: Tuple[str, str],\n",
    "    row_dict: Dict[str, Any],\n",
    "    variants: List[str],\n",
    ") -> Optional[AttemptResult]:\n",
    "    \"\"\"\n",
    "    Run a single attempt with a given strategy.\n",
    "    \"\"\"\n",
    "    strat_name, strat_text = strategy\n",
    "    print(f\"\\nâ–¶ Attempt {attempt_index + 1}: {strat_name}\")\n",
    "    prompt = build_super7_prompt(row_dict, strat_name, strat_text, variants)\n",
    "    obj = call_gemini_with_grounding(client, prompt)\n",
    "    if not obj:\n",
    "        print(\"  âš  Attempt failed (no valid JSON).\")\n",
    "        return None\n",
    "\n",
    "    obj = attach_scores(obj)\n",
    "    overall = obj.get(\"overall_confidence_score\", 0.0)\n",
    "    print(f\"  âœ” Attempt overall score: {overall}\")\n",
    "    return AttemptResult(\n",
    "        attempt_index=attempt_index,\n",
    "        strategy_name=strat_name,\n",
    "        raw_object=obj,\n",
    "        overall_score=overall,\n",
    "    )\n",
    "\n",
    "\n",
    "def process_company_row(\n",
    "    client: genai.Client,\n",
    "    row: pd.Series,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Full pipeline for a single company:\n",
    "    - generate name variants\n",
    "    - build 3 strategies\n",
    "    - retry up to MAX_RETRIES with early stop\n",
    "    - pick best attempt\n",
    "    - run second-pass enhanced search\n",
    "    - return final object\n",
    "    \"\"\"\n",
    "    row_dict = row.to_dict()\n",
    "    company_name = row_dict.get(\"company_name\", \"\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Processing company: {company_name}\")\n",
    "\n",
    "    variants = generate_name_variants(company_name)\n",
    "    strategies = build_search_strategies(row_dict, variants)\n",
    "\n",
    "    attempts: List[AttemptResult] = []\n",
    "\n",
    "    print(f\"=== RETRY ENGINE START (max {MAX_RETRIES} attempts, early-stop at {EARLY_STOP_THRESHOLD}) ===\")\n",
    "    for i in range(min(MAX_RETRIES, len(strategies))):\n",
    "        print(f\"\\n=== Running Attempt {i + 1}/{MAX_RETRIES} ===\")\n",
    "        res = run_single_attempt(client, i, strategies[i], row_dict, variants)\n",
    "        if res is None:\n",
    "            continue\n",
    "        attempts.append(res)\n",
    "        if res.overall_score >= EARLY_STOP_THRESHOLD:\n",
    "            print(f\"ðŸš€ Early stop triggered (score {res.overall_score} >= {EARLY_STOP_THRESHOLD})\")\n",
    "            break\n",
    "\n",
    "    if not attempts:\n",
    "        print(\"âŒ All attempts failed for this company.\")\n",
    "        return {\n",
    "            \"input\": row_dict,\n",
    "            \"error\": \"all_attempts_failed\",\n",
    "        }\n",
    "\n",
    "    # pick best attempt\n",
    "    best = max(attempts, key=lambda a: a.overall_score)\n",
    "    primary = best.raw_object\n",
    "    print(\n",
    "        f\"âœ… Primary winner: Attempt #{best.attempt_index + 1} \"\n",
    "        f\"({best.strategy_name}) with score {best.overall_score}\"\n",
    "    )\n",
    "\n",
    "    # SECOND PASS\n",
    "    second = run_second_pass_search(client, primary, row_dict, variants)\n",
    "    if second:\n",
    "        s_score = second.get(\"overall_confidence_score\", 0.0)\n",
    "        p_score = primary.get(\"overall_confidence_score\", 0.0)\n",
    "        if s_score > p_score:\n",
    "            print(f\"ðŸ” Second-pass improved score from {p_score} â†’ {s_score}. Using refined object.\")\n",
    "            final_obj = second\n",
    "        else:\n",
    "            print(f\"â„¹ Second-pass score {s_score} not better than primary {p_score}. Keeping primary.\")\n",
    "            final_obj = primary\n",
    "    else:\n",
    "        print(\"â„¹ Second-pass not executed or returned no better result. Keeping primary.\")\n",
    "        final_obj = primary\n",
    "\n",
    "    # attach some debug info\n",
    "    final_obj[\"best_attempt_index\"] = best.attempt_index\n",
    "    final_obj[\"best_strategy_name\"] = best.strategy_name\n",
    "    final_obj[\"input\"] = row_dict\n",
    "\n",
    "    return final_obj\n",
    "\n",
    "\n",
    "# ==================== CSV PIPELINE (PRINT-ONLY) ====================\n",
    "\n",
    "def process_csv_print_only(input_csv_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process an input CSV and print JSON results for each row.\n",
    "    No files are written; everything is printed for debugging.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv_path)\n",
    "    client = init_gemini_client()\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "    for idx, row in df.iterrows():\n",
    "        result = process_company_row(client, row)\n",
    "        results.append(result)\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Result for row {idx} (company: {row.get('company_name', '')})\")\n",
    "        print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ==================== CLI ENTRY (OPTIONAL) ====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Super-7 Vertex AI Extractor (print-only debug mode).\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--input_csv\",\n",
    "        required=True,\n",
    "        help=\"Path to input CSV file with company_name, country, etc.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    process_csv_print_only(args.input_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3af384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from super7_vertex import init_gemini_client, process_company_row\n",
    "import pandas as pd, json\n",
    "\n",
    "client = init_gemini_client()\n",
    "\n",
    "sample_row = pd.Series({\n",
    "    \"company_name\": \"ABC Global Solutions LLC\",\n",
    "    \"country\": \"United States\",\n",
    "    \"state_province\": \"California\",\n",
    "    \"city\": \"Los Angeles\",\n",
    "    \"postal_code\": \"\",\n",
    "    \"street_address\": \"\",\n",
    "    \"phone_number\": \"\",\n",
    "    \"additional_info\": \"\"\n",
    "})\n",
    "\n",
    "result = process_company_row(client, sample_row)\n",
    "print(json.dumps(result, indent=2, ensure_ascii=False))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
