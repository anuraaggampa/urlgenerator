{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01682cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "super7_docling_snippet_resolver.py\n",
    "\n",
    "Pipeline:\n",
    "- Input: list of Super7Input dicts (company_name required; others optional)\n",
    "- For each company:\n",
    "    1) Tavily search to get candidate URLs (+ title + snippet)\n",
    "    2) Search-level filter (title/snippet similarity vs company name)\n",
    "    3) ScraperTool (Docling-first) to get text from HTML-like pages\n",
    "       (now explicitly skips PDFs/Word/Excel/PPT by extension)\n",
    "    4) Doc-level filter (does text even mention the company?)\n",
    "    5) Snippet extraction:\n",
    "         - windows around company name\n",
    "         - regex-based address/phone/zip candidates\n",
    "    6) LLMExtractor runs on snippets (not full doc)\n",
    "    7) Super7 summarizer:\n",
    "         - same-company guard\n",
    "         - light scoring\n",
    "         - per-field best value + provenance\n",
    "\n",
    "Additional rules:\n",
    "- News domains (e.g. thetimes-tribune.com) are blacklisted as sources\n",
    "  and are not scraped or used as primary URLs.\n",
    "- Social media + DNB + news domains are never used as Super7 value sources.\n",
    "\n",
    "Scraping ethics:\n",
    "- Realistic browser User-Agent\n",
    "- requests.Session() to reuse cookies\n",
    "- small random delays between requests\n",
    "- domain blacklist for clearly hostile/irrelevant sites\n",
    "- size guard for huge documents\n",
    "- you are responsible for only scraping sites whose ToS/robots.txt allow it\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import re\n",
    "from typing import List, Optional, Dict, Any, Tuple\n",
    "from dataclasses import dataclass\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "from langchain_tavily import TavilySearch\n",
    "from docling.document_converter import DocumentConverter\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Setup\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "load_dotenv()\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise RuntimeError(\"Please set OPENAI_API_KEY in your environment.\")\n",
    "\n",
    "if not os.getenv(\"TAVILY_API_KEY\"):\n",
    "    print(\"[WARN] TAVILY_API_KEY is not set. Tavily search will fail.\")\n",
    "\n",
    "SUPER7_FIELDS = [\n",
    "    \"company_name\",\n",
    "    \"street_address\",\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"country\",\n",
    "    \"zip\",\n",
    "    \"phone\",\n",
    "]\n",
    "\n",
    "# Basic corp suffixes for name normalization\n",
    "CORP_SUFFIXES = {\n",
    "    \"llc\", \"l.l.c\", \"inc\", \"inc.\", \"corp\", \"corp.\", \"corporation\",\n",
    "    \"company\", \"co\", \"co.\", \"ltd\", \"ltd.\", \"limited\", \"plc\", \"s.a.\",\n",
    "    \"gmbh\", \"oy\", \"ab\", \"bv\", \"srl\", \"sas\", \"spa\", \"holdings\", \"holding\",\n",
    "}\n",
    "\n",
    "# News outlets we want to ignore for this use-case\n",
    "NEWS_DOMAIN_BLACKLIST = {\n",
    "    \"thetimes-tribune.com\",\n",
    "    \"www.thetimes-tribune.com\",\n",
    "    # add more if they show up as bad sources\n",
    "}\n",
    "\n",
    "# Domains we DO NOT want to use for Super7 fields (social + DNB + news)\n",
    "SUMMARY_DOMAIN_EXCLUDE = {\n",
    "    \"facebook.com\",\n",
    "    \"www.facebook.com\",\n",
    "    \"instagram.com\",\n",
    "    \"www.instagram.com\",\n",
    "    \"twitter.com\",\n",
    "    \"www.twitter.com\",\n",
    "    \"x.com\",\n",
    "    \"www.x.com\",\n",
    "    \"linkedin.com\",\n",
    "    \"www.linkedin.com\",\n",
    "    \"tiktok.com\",\n",
    "    \"www.tiktok.com\",\n",
    "    \"dnb.com\",\n",
    "    \"www.dnb.com\",\n",
    "}\n",
    "SUMMARY_DOMAIN_EXCLUDE |= NEWS_DOMAIN_BLACKLIST\n",
    "\n",
    "# Domains we know are hostile / blocked / not worth scraping directly\n",
    "SCRAPER_DOMAIN_BLACKLIST = {\n",
    "    \"firesupport.uk\",\n",
    "    \"www.firesupport.uk\",\n",
    "    \"search.sunbiz.org\",\n",
    "    \"bubba.ai\",\n",
    "    \"govtribe.com\",\n",
    "    \"www.govtribe.com\",\n",
    "    \"brokersnapshot.com\",\n",
    "    \"www.brokersnapshot.com\",\n",
    "    \"dnb.com\",\n",
    "    \"www.dnb.com\",\n",
    "    \"b2bhint.com\",\n",
    "    \"www.b2bhint.com\",\n",
    "    \"yelp.com\",\n",
    "    \"www.yelp.com\",\n",
    "    \"davids-tire-shop-service.wheree.com\",\n",
    "    \"wheree.com\",\n",
    "\n",
    "    # noisy big-PDF domains from your logs\n",
    "    \"luke.af.mil\",\n",
    "    \"www.luke.af.mil\",\n",
    "    \"nrc.gov\",\n",
    "    \"www.nrc.gov\",\n",
    "}\n",
    "SCRAPER_DOMAIN_BLACKLIST |= NEWS_DOMAIN_BLACKLIST\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def get_domain(url: str) -> Optional[str]:\n",
    "    if not url:\n",
    "        return None\n",
    "    try:\n",
    "        netloc = urlparse(url).netloc.lower()\n",
    "        if netloc.startswith(\"www.\"):\n",
    "            netloc = netloc[4:]\n",
    "        return netloc or None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_company_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize company name for similarity:\n",
    "      - lowercase\n",
    "      - & -> and\n",
    "      - remove punctuation\n",
    "      - drop typical corp suffixes\n",
    "    \"\"\"\n",
    "    if not name:\n",
    "        return \"\"\n",
    "\n",
    "    s = name.lower()\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "\n",
    "    trans_table = str.maketrans(\"\", \"\", string.punctuation.replace(\"&\", \"\"))\n",
    "    s = s.translate(trans_table)\n",
    "\n",
    "    tokens = s.split()\n",
    "    cleaned = [t for t in tokens if t not in CORP_SUFFIXES]\n",
    "    return \" \".join(cleaned).strip()\n",
    "\n",
    "\n",
    "def jaccard_name_similarity(a: str, b: str) -> float:\n",
    "    \"\"\"\n",
    "    Token Jaccard similarity between normalized names.\n",
    "    \"\"\"\n",
    "    na = normalize_company_name(a)\n",
    "    nb = normalize_company_name(b)\n",
    "    if not na or not nb:\n",
    "        return 0.0\n",
    "\n",
    "    set_a = set(na.split())\n",
    "    set_b = set(nb.split())\n",
    "    if not set_a or not set_b:\n",
    "        return 0.0\n",
    "\n",
    "    inter = len(set_a & set_b)\n",
    "    union = len(set_a | set_b)\n",
    "    return inter / union if union > 0 else 0.0\n",
    "\n",
    "\n",
    "def should_consider_search_result(\n",
    "    company_name: str,\n",
    "    title: str,\n",
    "    snippet: str,\n",
    "    min_sim: float = 0.2,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Cheap pre-filter: decide whether a Tavily result is even worth scraping.\n",
    "    - If title is somewhat similar OR snippet mentions the company name, keep.\n",
    "    - Otherwise, skip.\n",
    "    \"\"\"\n",
    "    if not title and not snippet:\n",
    "        return True  # be permissive if we know nothing\n",
    "\n",
    "    sim = jaccard_name_similarity(company_name, title or \"\")\n",
    "    if sim >= min_sim:\n",
    "        return True\n",
    "\n",
    "    if company_name and snippet:\n",
    "        if company_name.lower() in snippet.lower():\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def doc_mentions_company(s7_name: str, text: str, min_occurrences: int = 1) -> bool:\n",
    "    \"\"\"\n",
    "    Doc-level filter: does the text even look like it's about this company?\n",
    "\n",
    "    - Check if raw company_name (lowercased) appears.\n",
    "    - If not, check main token of normalized name.\n",
    "    \"\"\"\n",
    "    if not s7_name or not text:\n",
    "        return False\n",
    "\n",
    "    text_lower = text.lower()\n",
    "    if s7_name.lower() in text_lower:\n",
    "        return True\n",
    "\n",
    "    norm = normalize_company_name(s7_name)\n",
    "    tokens = norm.split()\n",
    "    if not tokens:\n",
    "        return False\n",
    "\n",
    "    main_token = tokens[0]\n",
    "    if not main_token:\n",
    "        return False\n",
    "\n",
    "    return text_lower.count(main_token) >= min_occurrences\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Snippet extraction\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "@dataclass\n",
    "class Snippet:\n",
    "    snippet_id: int\n",
    "    snippet_type: str  # \"name_context\" | \"address_candidate\" | \"phone_candidate\" | \"zip_candidate\" | \"generic\"\n",
    "    text: str\n",
    "\n",
    "\n",
    "def extract_snippets_for_company(\n",
    "    full_text: str,\n",
    "    company_name: str,\n",
    "    max_snippets: int = 25,\n",
    "    window_chars: int = 400,\n",
    ") -> List[Snippet]:\n",
    "    \"\"\"\n",
    "    Extract a small set of high-signal snippets from the full text:\n",
    "    - windows around company-name mentions\n",
    "    - regex candidates for phone / address / zip\n",
    "    \"\"\"\n",
    "    snippets: List[Snippet] = []\n",
    "    used_spans: List[Tuple[int, int]] = []\n",
    "\n",
    "    text = full_text or \"\"\n",
    "    if not text.strip():\n",
    "        return snippets\n",
    "\n",
    "    lower_text = text.lower()\n",
    "    norm_name = normalize_company_name(company_name)\n",
    "    raw_name = company_name.lower()\n",
    "    name_variants = set()\n",
    "    if norm_name:\n",
    "        name_variants.add(norm_name)\n",
    "    if raw_name:\n",
    "        name_variants.add(raw_name)\n",
    "    if \"&\" in raw_name:\n",
    "        name_variants.add(raw_name.replace(\"&\", \"and\"))\n",
    "\n",
    "    def add_snippet(start: int, end: int, snippet_type: str):\n",
    "        nonlocal snippets, used_spans\n",
    "        # de-duplicate overlapping spans\n",
    "        for s, e in used_spans:\n",
    "            if not (end <= s or start >= e):\n",
    "                return\n",
    "        chunk = text[start:end].strip()\n",
    "        if not chunk:\n",
    "            return\n",
    "        snippet_id = len(snippets) + 1\n",
    "        snippets.append(Snippet(snippet_id=snippet_id, snippet_type=snippet_type, text=chunk))\n",
    "        used_spans.append((start, end))\n",
    "\n",
    "    # --- 1) Name-anchored snippets ---\n",
    "    for variant in name_variants:\n",
    "        if not variant:\n",
    "            continue\n",
    "        idx = 0\n",
    "        while True:\n",
    "            idx = lower_text.find(variant, idx)\n",
    "            if idx == -1:\n",
    "                break\n",
    "            start = max(0, idx - window_chars)\n",
    "            end = min(len(text), idx + len(variant) + window_chars)\n",
    "            add_snippet(start, end, \"name_context\")\n",
    "            idx = idx + len(variant)\n",
    "            if len(snippets) >= max_snippets:\n",
    "                return snippets\n",
    "\n",
    "    # --- 2) Regex-based phone candidates ---\n",
    "    phone_pattern = re.compile(r\"\\+?\\d[\\d\\-\\s\\(\\)]{7,}\")\n",
    "    for m in phone_pattern.finditer(text):\n",
    "        start = max(0, m.start() - 80)\n",
    "        end = min(len(text), m.end() + 80)\n",
    "        add_snippet(start, end, \"phone_candidate\")\n",
    "        if len(snippets) >= max_snippets:\n",
    "            return snippets\n",
    "\n",
    "    # --- 3) Regex-based zip candidates (US-style, approximate) ---\n",
    "    zip_pattern = re.compile(r\"\\b\\d{5}(?:-\\d{4})?\\b\")\n",
    "    for m in zip_pattern.finditer(text):\n",
    "        start = max(0, m.start() - 80)\n",
    "        end = min(len(text), m.end() + 80)\n",
    "        add_snippet(start, end, \"zip_candidate\")\n",
    "        if len(snippets) >= max_snippets:\n",
    "            return snippets\n",
    "\n",
    "    # --- 4) Address-ish lines fallback (only if still few snippets) ---\n",
    "    if len(snippets) < max_snippets:\n",
    "        lines = text.splitlines()\n",
    "        address_keywords = [\n",
    "            \"street\", \"st.\", \"st \", \"road\", \"rd.\", \"rd \",\n",
    "            \"avenue\", \"ave.\", \"ave \", \"boulevard\", \"blvd\",\n",
    "            \"lane\", \"ln.\", \"ln \", \"drive\", \"dr.\", \"dr \",\n",
    "        ]\n",
    "        for line in lines:\n",
    "            l = line.lower()\n",
    "            if any(kw in l for kw in address_keywords) and any(ch.isdigit() for ch in l):\n",
    "                chunk = line.strip()\n",
    "                if not chunk:\n",
    "                    continue\n",
    "                snippet_id = len(snippets) + 1\n",
    "                snippets.append(Snippet(snippet_id=snippet_id, snippet_type=\"address_candidate\", text=chunk))\n",
    "                if len(snippets) >= max_snippets:\n",
    "                    break\n",
    "\n",
    "    # If we somehow got nothing, add a generic first N chars as a last resort\n",
    "    if not snippets:\n",
    "        chunk = text[:800].strip()\n",
    "        if chunk:\n",
    "            snippets.append(Snippet(snippet_id=1, snippet_type=\"generic\", text=chunk))\n",
    "\n",
    "    return snippets\n",
    "\n",
    "\n",
    "def snippets_to_prompt_block(snippets: List[Snippet]) -> str:\n",
    "    \"\"\"\n",
    "    Convert snippets into a textual block for the LLM prompt.\n",
    "    \"\"\"\n",
    "    if not snippets:\n",
    "        return \"No snippets were extracted; the document text was empty or uninformative.\"\n",
    "\n",
    "    lines = [\"Here are the extracted snippets (pre-filtered for likely relevance):\"]\n",
    "    for sn in snippets:\n",
    "        lines.append(f\"[SNIPPET {sn.snippet_id}] type={sn.snippet_type}\")\n",
    "        lines.append(sn.text)\n",
    "        lines.append(\"\")  # blank line between snippets\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Models\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class Super7Input(BaseModel):\n",
    "    company_name: str\n",
    "    country: Optional[str] = None\n",
    "    state: Optional[str] = None\n",
    "    city: Optional[str] = None\n",
    "    street_address: Optional[str] = None\n",
    "    zip: Optional[str] = None\n",
    "    phone: Optional[str] = None\n",
    "\n",
    "\n",
    "class ExtractedEntity(BaseModel):\n",
    "    entity_type: str\n",
    "    value: str\n",
    "    source_urls: List[str] = Field(default_factory=list)\n",
    "    confidence: Optional[float] = None  # should be in [0,1]\n",
    "\n",
    "\n",
    "class PageExtractionResult(BaseModel):\n",
    "    url: str\n",
    "    entities: List[ExtractedEntity] = Field(default_factory=list)\n",
    "    match_score_name: float = 0.0\n",
    "    match_score_address: float = 0.0\n",
    "    match_score_phone: float = 0.0\n",
    "    looks_like_official_site: bool = False\n",
    "    overall_score: float = 0.0\n",
    "    reason: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CandidateRecord:\n",
    "    url: str\n",
    "    source_type: str\n",
    "    extraction: PageExtractionResult\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Web search\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class WebSearchTool:\n",
    "    def __init__(self, max_results: int = 5):\n",
    "        key = os.getenv(\"TAVILY_API_KEY\")\n",
    "        if not key:\n",
    "            raise RuntimeError(\"Missing TAVILY_API_KEY.\")\n",
    "        self.tool = TavilySearch(max_results=max_results, tavily_api_key=key)\n",
    "\n",
    "    def search(self, queries: List[str]) -> List[Dict[str, Any]]:\n",
    "        seen: Dict[str, Dict[str, Any]] = {}\n",
    "        for q in queries:\n",
    "            res = self.tool.invoke({\"query\": q})\n",
    "            for r in res.get(\"results\", []):\n",
    "                url = r.get(\"url\")\n",
    "                if not url:\n",
    "                    continue\n",
    "                if url not in seen:\n",
    "                    seen[url] = {\n",
    "                        \"url\": url,\n",
    "                        \"title\": r.get(\"title\", \"\"),\n",
    "                        \"source_type\": \"web_search\",\n",
    "                        \"content\": r.get(\"content\", \"\"),\n",
    "                    }\n",
    "        return list(seen.values())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# ScraperTool using Docling + polite crawling + size guard\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class ScraperTool:\n",
    "    \"\"\"\n",
    "    Scraper that prefers Docling for rich formats (but now explicitly\n",
    "    skips PDFs/Word/Excel/PPT by extension), and falls back to HTML +\n",
    "    BeautifulSoup if Docling fails.\n",
    "\n",
    "    - Realistic browser-like User-Agent\n",
    "    - requests.Session() to persist cookies\n",
    "    - small random delays between requests (throttling)\n",
    "    - domain blacklist\n",
    "    - size guard for large documents\n",
    "\n",
    "    Returns plain text/markdown truncated to max_chars.\n",
    "    \"\"\"\n",
    "\n",
    "    SKIP_EXTENSIONS = (\n",
    "        \".pdf\",\n",
    "        \".doc\",\n",
    "        \".docx\",\n",
    "        \".xls\",\n",
    "        \".xlsx\",\n",
    "        \".ppt\",\n",
    "        \".pptx\",\n",
    "    )\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        timeout: int = 10,\n",
    "        delay_range: tuple = (1.0, 3.0),\n",
    "        use_markdown: bool = True,\n",
    "        max_content_length_bytes: int = 8_000_000,  # ~8 MB limit\n",
    "    ):\n",
    "        self.timeout = timeout\n",
    "        self.delay_range = delay_range\n",
    "        self.use_markdown = use_markdown\n",
    "        self.max_content_length_bytes = max_content_length_bytes\n",
    "\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/120.0.0.0 Safari/537.36\"\n",
    "            ),\n",
    "            \"Accept\": (\n",
    "                \"text/html,application/xhtml+xml,application/xml;\"\n",
    "                \"q=0.9,image/avif,image/webp,*/*;q=0.8\"\n",
    "            ),\n",
    "            \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "            \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "            \"Connection\": \"keep-alive\",\n",
    "        })\n",
    "\n",
    "        self.converter = DocumentConverter()\n",
    "\n",
    "    def _delay(self):\n",
    "        lo, hi = self.delay_range\n",
    "        if hi > 0:\n",
    "            time.sleep(random.uniform(lo, hi))\n",
    "\n",
    "    def _scrape_html_basic(self, html: str) -> str:\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for tag in soup([\"script\", \"style\", \"noscript\"]):\n",
    "            tag.decompose()\n",
    "        return \"\\n\".join(\n",
    "            line.strip()\n",
    "            for line in soup.get_text(\"\\n\").splitlines()\n",
    "            if line.strip()\n",
    "        )\n",
    "\n",
    "    def _head_too_large(self, url: str) -> bool:\n",
    "        \"\"\"\n",
    "        Lightweight HEAD to check Content-Length before we download/convert.\n",
    "        If the file is larger than max_content_length_bytes, we skip it.\n",
    "        \"\"\"\n",
    "        if not self.max_content_length_bytes:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            self._delay()\n",
    "            resp = self.session.head(url, timeout=self.timeout, allow_redirects=True)\n",
    "        except requests.RequestException:\n",
    "            # If HEAD fails, don't block; we'll let normal flow decide.\n",
    "            return False\n",
    "\n",
    "        cl = resp.headers.get(\"Content-Length\")\n",
    "        if cl is None:\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            size = int(cl)\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "        if size > self.max_content_length_bytes:\n",
    "            print(f\"[SCRAPER] Skipping {url} (size {size} > {self.max_content_length_bytes} bytes).\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def fetch(self, url: str, max_chars: int = 50000) -> str:\n",
    "        domain = get_domain(url) or \"\"\n",
    "        if domain in SCRAPER_DOMAIN_BLACKLIST:\n",
    "            # known problematic or unwanted domains\n",
    "            return \"\"\n",
    "\n",
    "        # Skip PDFs / Word / Excel / PPT by extension\n",
    "        path = urlparse(url).path.lower()\n",
    "        if any(path.endswith(ext) for ext in self.SKIP_EXTENSIONS):\n",
    "            # For this project, we ignore non-HTML docs\n",
    "            return \"\"\n",
    "\n",
    "        # Quick size check first (for large docs)\n",
    "        if self._head_too_large(url):\n",
    "            return \"\"\n",
    "\n",
    "        # 1) Try Docling directly with URL (for HTML-like content)\n",
    "        try:\n",
    "            self._delay()\n",
    "            result = self.converter.convert(url)\n",
    "            doc = result.document\n",
    "\n",
    "            if self.use_markdown:\n",
    "                text = doc.export_to_markdown()\n",
    "            else:\n",
    "                text = doc.export_to_markdown()  # markdown is fine for LLM\n",
    "\n",
    "            if text:\n",
    "                if len(text) > max_chars:\n",
    "                    text = text[:max_chars]\n",
    "                return text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[SCRAPER] Docling failed for {url}: {e}\")\n",
    "\n",
    "        # 2) Fallback: raw HTML\n",
    "        try:\n",
    "            self._delay()\n",
    "            resp = self.session.get(url, timeout=self.timeout, allow_redirects=True)\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"[SCRAPER] Failed {url}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "        if resp.status_code in (401, 403, 429):\n",
    "            print(f\"[SCRAPER] HTTP {resp.status_code} for {url}, skipping.\")\n",
    "            return \"\"\n",
    "\n",
    "        try:\n",
    "            resp.raise_for_status()\n",
    "        except requests.HTTPError as e:\n",
    "            print(f\"[SCRAPER] HTTP error {resp.status_code} for {url}: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "        text = self._scrape_html_basic(resp.text)\n",
    "        if len(text) > max_chars:\n",
    "            text = text[:max_chars]\n",
    "        return text\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# LLM Extractor (snippet-based)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class LLMExtractor:\n",
    "    \"\"\"\n",
    "    Handles calls to ChatGPT to:\n",
    "    - Extract entities from snippets\n",
    "    - Compute match scores vs Super7Input\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = \"gpt-4o-mini\", temperature: float = 0.0):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _safe_float(value, default: float = 0.0) -> float:\n",
    "        \"\"\"Convert value to float, handling None and bad types gracefully.\"\"\"\n",
    "        if value is None:\n",
    "            return default\n",
    "        try:\n",
    "            return float(value)\n",
    "        except (TypeError, ValueError):\n",
    "            return default\n",
    "\n",
    "    def build_prompt_from_snippets(\n",
    "        self,\n",
    "        s7: Super7Input,\n",
    "        url: str,\n",
    "        snippets: List[Snippet],\n",
    "    ) -> str:\n",
    "        s7_json = json.dumps(s7.model_dump(), indent=2)\n",
    "        snippet_block = snippets_to_prompt_block(snippets)\n",
    "\n",
    "        return f\"\"\"\n",
    "You are an information extraction assistant.\n",
    "\n",
    "You are given:\n",
    "- A target company Super7 input\n",
    "- A URL\n",
    "- A small set of text snippets extracted from that URL, pre-filtered for relevance\n",
    "\n",
    "Your job is to extract entities using these exact entity_type values when applicable:\n",
    "\n",
    "Super7-related:\n",
    "- \"company_name\"\n",
    "- \"street_address\"\n",
    "- \"city\"\n",
    "- \"state\"\n",
    "- \"country\"\n",
    "- \"zip\"\n",
    "- \"phone\"\n",
    "\n",
    "Identifier-related:\n",
    "- \"dot_number\"\n",
    "- \"registration_id\"\n",
    "- \"tax_id\"\n",
    "- \"mc_number\"\n",
    "\n",
    "Other:\n",
    "- \"industry\"\n",
    "- \"email\"\n",
    "- \"website\"\n",
    "- \"social_link\"\n",
    "- \"director\"\n",
    "- \"other\"\n",
    "\n",
    "For each entity:\n",
    "- entity_type: one of the above strings\n",
    "- value: string\n",
    "- source_urls: array of URLs (MUST include \"{url}\" at minimum)\n",
    "- confidence: 0.0 to 1.0\n",
    "\n",
    "Also compute:\n",
    "- match_score_name: 0.0 to 1.0 (how well the snippets match the company name)\n",
    "- match_score_address: 0.0 to 1.0\n",
    "- match_score_phone: 0.0 to 1.0\n",
    "- looks_like_official_site: true/false (is this likely the official website / main profile?)\n",
    "- overall_score: 0.0 to 1.0 (summary of how relevant this URL is to the company)\n",
    "- reason: short explanation\n",
    "\n",
    "Important:\n",
    "- The snippets may contain other companies or entities; only extract entities that clearly belong to the target company.\n",
    "- Be conservative with confidence and scores; if unsure, use lower values.\n",
    "\n",
    "Return STRICT JSON ONLY in this shape (no extra commentary):\n",
    "\n",
    "{{\n",
    "  \"url\": \"{url}\",\n",
    "  \"entities\": [\n",
    "    {{\n",
    "      \"entity_type\": \"company_name\" | \"street_address\" | \"city\" | \"state\" | \"country\" | \"zip\" | \"phone\" |\n",
    "                      \"dot_number\" | \"registration_id\" | \"tax_id\" | \"mc_number\" |\n",
    "                      \"industry\" | \"email\" | \"website\" | \"social_link\" | \"director\" | \"other\",\n",
    "      \"value\": \"<string>\",\n",
    "      \"source_urls\": [\"<url1>\", \"<url2>\", \"...\"],\n",
    "      \"confidence\": <number between 0 and 1 or null>\n",
    "    }}\n",
    "  ],\n",
    "  \"match_score_name\": <0..1>,\n",
    "  \"match_score_address\": <0..1>,\n",
    "  \"match_score_phone\": <0..1>,\n",
    "  \"looks_like_official_site\": <true or false>,\n",
    "  \"overall_score\": <0..1>,\n",
    "  \"reason\": \"<short explanation>\"\n",
    "}}\n",
    "\n",
    "Super7 input (hints, may be null):\n",
    "{s7_json}\n",
    "\n",
    "URL: {url}\n",
    "\n",
    "{snippet_block}\n",
    "\"\"\"\n",
    "\n",
    "    def extract_from_snippets(\n",
    "        self,\n",
    "        s7: Super7Input,\n",
    "        url: str,\n",
    "        snippets: List[Snippet],\n",
    "    ) -> PageExtractionResult:\n",
    "        if not snippets:\n",
    "            return PageExtractionResult(url=url)\n",
    "\n",
    "        prompt = self.build_prompt_from_snippets(s7, url, snippets)\n",
    "        resp = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        raw = resp.choices[0].message.content or \"\"\n",
    "\n",
    "        try:\n",
    "            data = json.loads(raw)\n",
    "        except Exception:\n",
    "            start = raw.find(\"{\")\n",
    "            end = raw.rfind(\"}\")\n",
    "            if start != -1 and end != -1 and end > start:\n",
    "                try:\n",
    "                    data = json.loads(raw[start:end + 1])\n",
    "                except Exception:\n",
    "                    data = {}\n",
    "            else:\n",
    "                data = {}\n",
    "\n",
    "        url_out = str(data.get(\"url\") or url)\n",
    "        ents: List[ExtractedEntity] = []\n",
    "\n",
    "        for e in data.get(\"entities\", []):\n",
    "            raw_type = e.get(\"entity_type\")\n",
    "            entity_type = \"other\" if raw_type is None else (str(raw_type) or \"other\")\n",
    "\n",
    "            raw_value = e.get(\"value\")\n",
    "            value = \"\" if raw_value is None else str(raw_value)\n",
    "\n",
    "            raw_srcs = e.get(\"source_urls\") or []\n",
    "            srcs = [str(s) for s in raw_srcs if s]\n",
    "            if url_out not in srcs:\n",
    "                srcs.append(url_out)\n",
    "\n",
    "            raw_conf = e.get(\"confidence\")\n",
    "            if isinstance(raw_conf, (int, float)):\n",
    "                confidence = max(0.0, min(float(raw_conf), 1.0))\n",
    "            else:\n",
    "                confidence = 0.0\n",
    "\n",
    "            ents.append(\n",
    "                ExtractedEntity(\n",
    "                    entity_type=entity_type,\n",
    "                    value=value,\n",
    "                    source_urls=srcs,\n",
    "                    confidence=confidence,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return PageExtractionResult(\n",
    "            url=url_out,\n",
    "            entities=ents,\n",
    "            match_score_name=float(data.get(\"match_score_name\", 0.0)),\n",
    "            match_score_address=float(data.get(\"match_score_address\", 0.0)),\n",
    "            match_score_phone=float(data.get(\"match_score_phone\", 0.0)),\n",
    "            looks_like_official_site=bool(data.get(\"looks_like_official_site\", False)),\n",
    "            overall_score=float(data.get(\"overall_score\", 0.0)),\n",
    "            reason=str(data.get(\"reason\", \"\")),\n",
    "        )\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Simple scoring + same-company guard\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def score_field_candidate(\n",
    "    field: str,\n",
    "    s7: Super7Input,\n",
    "    ent: ExtractedEntity,\n",
    "    page: PageExtractionResult,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Simple scoring for a candidate entity (raw score, not normalized).\n",
    "\n",
    "    raw_score =\n",
    "        ent_confidence\n",
    "      + 0.5 * page_overall_score\n",
    "      + 0.2 if looks_like_official_site\n",
    "      + bonus if matches Super7 hint\n",
    "    \"\"\"\n",
    "    conf = ent.confidence if isinstance(ent.confidence, (int, float)) else 0.0\n",
    "    score = conf + 0.5 * page.overall_score\n",
    "    if page.looks_like_official_site:\n",
    "        score += 0.2\n",
    "\n",
    "    hint = getattr(s7, field, None)\n",
    "    if hint:\n",
    "        h = hint.lower().strip()\n",
    "        v = ent.value.lower().strip()\n",
    "        if v == h:\n",
    "            score += 0.3\n",
    "        elif h in v or v in h:\n",
    "            score += 0.15\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def is_page_same_company(\n",
    "    s7: Super7Input,\n",
    "    page: PageExtractionResult,\n",
    "    min_sim: float = 0.6,\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Minimal same-company guard:\n",
    "    - Look at extracted company_name entities on this page.\n",
    "    - Compute name similarity vs. target company_name.\n",
    "    - If any >= min_sim, treat as same company.\n",
    "    - If no company_name entities at all, we allow the page (can't decide).\n",
    "    \"\"\"\n",
    "    target = s7.company_name\n",
    "    if not target:\n",
    "        return True\n",
    "\n",
    "    sims = []\n",
    "    for e in page.entities:\n",
    "        if e.entity_type == \"company_name\" and e.value:\n",
    "            sims.append(jaccard_name_similarity(target, e.value))\n",
    "\n",
    "    if not sims:\n",
    "        # no explicit company_name extracted; don't block\n",
    "        return True\n",
    "\n",
    "    best_sim = max(sims)\n",
    "    return best_sim >= min_sim\n",
    "\n",
    "\n",
    "def summarize_super7_simple(\n",
    "    s7: Super7Input,\n",
    "    candidates: List[CandidateRecord],\n",
    ") -> Dict[str, Optional[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Collect all entities from all pages and pick best per Super7 field.\n",
    "\n",
    "    For non-company_name fields, we require the page to be \"same company\"\n",
    "    according to is_page_same_company().\n",
    "\n",
    "    The returned \"confidence\" is normalized into [0,1].\n",
    "    \"\"\"\n",
    "    summary: Dict[str, Optional[Dict[str, Any]]] = {}\n",
    "\n",
    "    # max possible raw_score ~ 2.0 (conf 1 + 0.5*1 + 0.2 + 0.3)\n",
    "    RAW_SCORE_MAX = 2.0\n",
    "\n",
    "    for field in SUPER7_FIELDS:\n",
    "        best_ent = None\n",
    "        best_page = None\n",
    "        best_raw_score = -1.0\n",
    "\n",
    "        for rec in candidates:\n",
    "            page = rec.extraction\n",
    "\n",
    "            # For non-name fields, enforce same-company guard\n",
    "            if field != \"company_name\" and not is_page_same_company(s7, page):\n",
    "                continue\n",
    "\n",
    "            for ent in page.entities:\n",
    "                if ent.entity_type != field:\n",
    "                    continue\n",
    "                if not ent.value:\n",
    "                    continue\n",
    "\n",
    "                # Skip if ALL sources are excluded domains\n",
    "                allowed_sources = []\n",
    "                for src in ent.source_urls:\n",
    "                    d = get_domain(src)\n",
    "                    if d and d in SUMMARY_DOMAIN_EXCLUDE:\n",
    "                        continue\n",
    "                    allowed_sources.append(src)\n",
    "                if not allowed_sources:\n",
    "                    continue\n",
    "\n",
    "                raw_score = score_field_candidate(field, s7, ent, page)\n",
    "                if raw_score > best_raw_score:\n",
    "                    best_raw_score = raw_score\n",
    "                    best_ent = ent\n",
    "                    best_page = page\n",
    "\n",
    "        # if no good candidate, set None\n",
    "        if not best_ent or best_raw_score < 0.3:\n",
    "            summary[field] = None\n",
    "        else:\n",
    "            # normalize raw_score into [0,1] for exposed confidence\n",
    "            norm_conf = best_raw_score / RAW_SCORE_MAX\n",
    "            norm_conf = max(0.0, min(norm_conf, 1.0))\n",
    "\n",
    "            all_sources = list({s for s in best_ent.source_urls if s})\n",
    "            primary_source = all_sources[0] if all_sources else (best_page.url if best_page else \"\")\n",
    "            summary[field] = {\n",
    "                \"value\": best_ent.value,\n",
    "                \"source\": primary_source,\n",
    "                \"confidence\": norm_conf,\n",
    "                \"all_sources\": all_sources,\n",
    "            }\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Resolver\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "class Super7Resolver:\n",
    "    def __init__(\n",
    "        self,\n",
    "        search: WebSearchTool,\n",
    "        scraper: ScraperTool,\n",
    "        extractor: LLMExtractor,\n",
    "    ):\n",
    "        self.search = search\n",
    "        self.scraper = scraper\n",
    "        self.extractor = extractor\n",
    "\n",
    "    def build_queries(self, s7: Super7Input) -> List[str]:\n",
    "        name = s7.company_name.strip()\n",
    "        parts = [name]\n",
    "        if s7.city:\n",
    "            parts.append(s7.city)\n",
    "        if s7.state:\n",
    "            parts.append(s7.state)\n",
    "        if s7.country:\n",
    "            parts.append(s7.country)\n",
    "        base = \" \".join(parts)\n",
    "\n",
    "        queries = [\n",
    "            f\"{base} official website\",\n",
    "            f\"{base} company\",\n",
    "            f\"\\\"{name}\\\"\",\n",
    "        ]\n",
    "        if s7.phone:\n",
    "            queries.append(f\"\\\"{name}\\\" \\\"{s7.phone}\\\"\")\n",
    "        return queries\n",
    "\n",
    "    def process_company(self, s7: Super7Input) -> Dict[str, Any]:\n",
    "        queries = self.build_queries(s7)\n",
    "        search_results = self.search.search(queries)\n",
    "\n",
    "        candidate_records: List[CandidateRecord] = []\n",
    "        primary_url = None\n",
    "        primary_conf = 0.0\n",
    "\n",
    "        for meta in search_results:\n",
    "            url = meta[\"url\"]\n",
    "            domain = get_domain(url) or \"\"\n",
    "            if domain in NEWS_DOMAIN_BLACKLIST:\n",
    "                # For this use-case, we ignore news outlets entirely\n",
    "                continue\n",
    "\n",
    "            title = meta.get(\"title\") or \"\"\n",
    "            snippet_text = meta.get(\"content\") or \"\"\n",
    "\n",
    "            # 1) Search-level filter\n",
    "            if not should_consider_search_result(s7.company_name, title, snippet_text):\n",
    "                continue\n",
    "\n",
    "            # 2) Scrape / convert\n",
    "            full_text = self.scraper.fetch(url)\n",
    "            if not full_text.strip():\n",
    "                # fallback to Tavily snippet if nothing else\n",
    "                if not snippet_text:\n",
    "                    continue\n",
    "                full_text = snippet_text\n",
    "\n",
    "            # 3) Doc-level filter\n",
    "            if not doc_mentions_company(s7.company_name, full_text):\n",
    "                continue\n",
    "\n",
    "            # 4) Snippet extraction\n",
    "            snippets = extract_snippets_for_company(full_text, s7.company_name)\n",
    "            if not snippets:\n",
    "                continue\n",
    "\n",
    "            # 5) LLM extraction on snippets\n",
    "            extraction = self.extractor.extract_from_snippets(s7, url, snippets)\n",
    "            candidate_records.append(\n",
    "                CandidateRecord(\n",
    "                    url=url,\n",
    "                    source_type=meta.get(\"source_type\", \"web_search\"),\n",
    "                    extraction=extraction,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if extraction.overall_score > primary_conf:\n",
    "                primary_conf = extraction.overall_score\n",
    "                primary_url = url\n",
    "\n",
    "        super7_summary = summarize_super7_simple(s7, candidate_records)\n",
    "\n",
    "        return {\n",
    "            \"input\": s7.model_dump(),\n",
    "            \"primary_url\": primary_url,\n",
    "            \"primary_confidence\": primary_conf,\n",
    "            \"candidates\": [\n",
    "                {\n",
    "                    \"url\": r.url,\n",
    "                    \"overall_score\": r.extraction.overall_score,\n",
    "                    \"reason\": r.extraction.reason,\n",
    "                }\n",
    "                for r in candidate_records\n",
    "            ],\n",
    "            \"super7_summary\": super7_summary,\n",
    "        }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Batch API\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def resolve_super7_batch(super7_payloads: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    super7_payloads: list of dicts with at least \"company_name\".\n",
    "    Returns: {\"results\": [ ... per-company dict ... ]}\n",
    "    \"\"\"\n",
    "    search = WebSearchTool(max_results=5)\n",
    "    scraper = ScraperTool(\n",
    "        timeout=10,\n",
    "        delay_range=(1.5, 4.0),\n",
    "        max_content_length_bytes=8_000_000,\n",
    "    )\n",
    "    extractor = LLMExtractor(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "    resolver = Super7Resolver(search, scraper, extractor)\n",
    "\n",
    "    results = []\n",
    "    for payload in super7_payloads:\n",
    "        s7 = Super7Input(**payload)\n",
    "        out = resolver.process_company(s7)\n",
    "        results.append(out)\n",
    "\n",
    "    return {\"results\": results}\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Manual test\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     batch_input  =  [\n",
    "#         {\n",
    "#             \"company_name\": \"2\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"Home Fit solutions LLC\",\n",
    "\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"David's Tireshop\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"Closhare LLc\",\n",
    "\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"Nexapoint Holding\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"Making you happy logistics llc\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"butler & associates construction,inc\",\n",
    "#         },\n",
    "#         {\n",
    "#             \"company_name\": \"focus wound care centre\",\n",
    "#         }\n",
    "#     ]\n",
    "#     res = resolve_super7_batch(batch_input)\n",
    "#     print(json.dumps(res, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e131a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://twoclickfit.com/privacy/: 404 Client Error: Not Found for url: https://twoclickfit.com/privacy/\n",
      "[SCRAPER] HTTP error 404 for https://twoclickfit.com/privacy/: 404 Client Error: Not Found for url: https://twoclickfit.com/privacy/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:42:37,605 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:42:37,627 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:42:37,628 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-17 17:42:37,674 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-11-17 17:42:37,685 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-11-17 17:42:37,686 - INFO - Processing document file\n",
      "2025-11-17 17:42:37,710 - INFO - Finished converting document file in 1.53 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.crunchbase.com/organization/2clickfit: 403 Client Error: Forbidden for url: https://www.crunchbase.com/organization/2clickfit\n",
      "[SCRAPER] HTTP 403 for https://www.crunchbase.com/organization/2clickfit, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:43:09,787 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:43:09,832 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:43:09,833 - INFO - Processing document 2clickfit-inc.html\n",
      "2025-11-17 17:43:09,888 - INFO - Finished converting document 2clickfit-inc.html in 1.30 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.secinfo.com/$/SEC/Registrant.asp?CIK=2094237: HTTPSConnectionPool(host='www.secinfo.com', port=443): Max retries exceeded with url: /$/SEC/Registrant.asp?CIK=2094237 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))\n",
      "[SCRAPER] Failed https://www.secinfo.com/$/SEC/Registrant.asp?CIK=2094237: HTTPSConnectionPool(host='www.secinfo.com', port=443): Max retries exceeded with url: /$/SEC/Registrant.asp?CIK=2094237 (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:43:27,649 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:43:27,671 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:43:27,672 - INFO - Processing document 2clickfit-inc\n",
      "2025-11-17 17:43:27,679 - INFO - Finished converting document 2clickfit-inc in 0.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.streetinsider.com/SEC+Filings/Form+D+2ClickFit%2C+Inc./25521440.html: 403 Client Error: Forbidden for url: https://www.streetinsider.com/SEC+Filings/Form+D+2ClickFit%2C+Inc./25521440.html\n",
      "[SCRAPER] HTTP 403 for https://www.streetinsider.com/SEC+Filings/Form+D+2ClickFit%2C+Inc./25521440.html, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:44:02,652 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:44:02,694 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:44:02,694 - INFO - Processing document 529-technologies\n",
      "2025-11-17 17:44:02,713 - INFO - Finished converting document 529-technologies in 0.51 sec.\n",
      "2025-11-17 17:44:16,214 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:44:16,220 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:44:16,221 - INFO - Processing document file\n",
      "2025-11-17 17:44:16,231 - INFO - Finished converting document file in 0.03 sec.\n",
      "2025-11-17 17:44:29,629 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:44:29,653 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:44:29,654 - INFO - Processing document file\n",
      "2025-11-17 17:44:29,709 - INFO - Finished converting document file in 0.48 sec.\n",
      "2025-11-17 17:44:42,681 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:44:42,719 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:44:42,720 - INFO - Processing document 529-plans\n",
      "2025-11-17 17:44:42,750 - INFO - Finished converting document 529-plans in 1.36 sec.\n",
      "2025-11-17 17:44:57,602 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:44:57,611 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:44:57,612 - INFO - Processing document 529-tech-llc.html\n",
      "2025-11-17 17:44:57,660 - INFO - Finished converting document 529-tech-llc.html in 1.23 sec.\n",
      "2025-11-17 17:45:09,995 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:45:10,053 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:45:10,055 - INFO - Processing document id6745104853\n",
      "2025-11-17 17:45:10,120 - INFO - Finished converting document id6745104853 in 0.73 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://iphone.apkpure.com/app/flyenjoy/com.test.flyenjoy: 403 Client Error: Forbidden for url: https://iphone.apkpure.com/app/flyenjoy/com.test.flyenjoy\n",
      "[SCRAPER] HTTP 403 for https://iphone.apkpure.com/app/flyenjoy/com.test.flyenjoy, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:45:36,470 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:45:36,485 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:45:36,485 - INFO - Processing document file\n",
      "2025-11-17 17:45:36,501 - INFO - Finished converting document file in 0.11 sec.\n",
      "2025-11-17 17:45:45,384 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:45:45,403 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:45:45,403 - INFO - Processing document 901-Tax-Pros-100095787630640\n",
      "2025-11-17 17:45:45,403 - INFO - Finished converting document 901-Tax-Pros-100095787630640 in 0.62 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/p/901-Tax-Pros-100095787630640/: 400 Client Error: Bad Request for url: https://www.facebook.com/p/901-Tax-Pros-100095787630640/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:45:59,558 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:45:59,569 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:45:59,569 - INFO - Processing document DGBbTs8xXJ4\n",
      "2025-11-17 17:45:59,569 - INFO - Finished converting document DGBbTs8xXJ4 in 0.91 sec.\n",
      "2025-11-17 17:46:11,798 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:46:11,839 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:46:11,839 - INFO - Processing document file\n",
      "2025-11-17 17:46:11,884 - INFO - Finished converting document file in 2.34 sec.\n",
      "2025-11-17 17:46:17,703 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:46:17,715 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:46:17,716 - INFO - Processing document 508644161510000\n",
      "2025-11-17 17:46:17,718 - INFO - Finished converting document 508644161510000 in 0.92 sec.\n",
      "2025-11-17 17:46:28,870 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:46:28,879 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:46:28,880 - INFO - Processing document 901-tax-pros-llc\n",
      "2025-11-17 17:46:28,895 - INFO - Finished converting document 901-tax-pros-llc in 0.44 sec.\n",
      "2025-11-17 17:47:01,379 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:47:01,386 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:47:01,386 - INFO - Processing document a2exteriors\n",
      "2025-11-17 17:47:01,392 - INFO - Finished converting document a2exteriors in 0.62 sec.\n",
      "2025-11-17 17:47:07,816 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:47:07,833 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:47:07,833 - INFO - Processing document file\n",
      "2025-11-17 17:47:07,862 - INFO - Finished converting document file in 0.09 sec.\n",
      "2025-11-17 17:47:14,950 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:47:14,965 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:47:14,965 - INFO - Processing document a2-exteriors-llc.html\n",
      "2025-11-17 17:47:15,003 - INFO - Finished converting document a2-exteriors-llc.html in 1.27 sec.\n",
      "2025-11-17 17:47:37,767 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:47:37,815 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:47:37,815 - INFO - Processing document services\n",
      "2025-11-17 17:47:37,901 - INFO - Finished converting document services in 9.17 sec.\n",
      "2025-11-17 17:47:55,181 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:47:55,194 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:47:55,195 - INFO - Processing document a2-weatherproofing-llc-springfield\n",
      "2025-11-17 17:47:55,210 - INFO - Finished converting document a2-weatherproofing-llc-springfield in 0.69 sec.\n",
      "2025-11-17 17:48:09,398 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:48:09,404 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:48:09,404 - INFO - Processing document 1480557592917751\n",
      "2025-11-17 17:48:09,412 - INFO - Finished converting document 1480557592917751 in 0.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/groups/864305987876251/posts/1480557592917751/: 400 Client Error: Bad Request for url: https://www.facebook.com/groups/864305987876251/posts/1480557592917751/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:48:24,479 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:48:24,497 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:48:24,500 - INFO - Processing document 864305987876251\n",
      "2025-11-17 17:48:24,502 - INFO - Finished converting document 864305987876251 in 1.03 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/groups/864305987876251/: 400 Client Error: Bad Request for url: https://www.facebook.com/groups/864305987876251/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:48:39,755 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:48:39,764 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:48:39,764 - INFO - Processing document 7762970760384647\n",
      "2025-11-17 17:48:39,764 - INFO - Finished converting document 7762970760384647 in 0.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/groups/1364647736883680/posts/7762970760384647/: 400 Client Error: Bad Request for url: https://www.facebook.com/groups/1364647736883680/posts/7762970760384647/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:48:56,501 - INFO - detected formats: [<InputFormat.XML_USPTO: 'xml_uspto'>]\n",
      "2025-11-17 17:48:56,502 - ERROR - Input document pressure-washing with format None does not match any allowed format: (dict_keys([<InputFormat.DOCX: 'docx'>, <InputFormat.PPTX: 'pptx'>, <InputFormat.HTML: 'html'>, <InputFormat.IMAGE: 'image'>, <InputFormat.PDF: 'pdf'>, <InputFormat.ASCIIDOC: 'asciidoc'>, <InputFormat.MD: 'md'>, <InputFormat.CSV: 'csv'>, <InputFormat.XLSX: 'xlsx'>, <InputFormat.XML_USPTO: 'xml_uspto'>, <InputFormat.XML_JATS: 'xml_jats'>, <InputFormat.METS_GBS: 'mets_gbs'>, <InputFormat.JSON_DOCLING: 'json_docling'>, <InputFormat.AUDIO: 'audio'>, <InputFormat.VTT: 'vtt'>]))\n",
      "2025-11-17 17:48:56,503 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.thumbtack.com/ct/norwich/pressure-washing: File format not allowed: pressure-washing\n",
      "[SCRAPER] Docling failed for https://www.zoominfo.com/c/aaf-logistics-inc/346190257: 403 Client Error: Forbidden for url: https://www.zoominfo.com/c/aaf-logistics-inc/346190257\n",
      "[SCRAPER] HTTP 403 for https://www.zoominfo.com/c/aaf-logistics-inc/346190257, skipping.\n",
      "[SCRAPER] Docling failed for https://seamless.ai/b/aaf-logistics-inc-147131241: 403 Client Error: Forbidden for url: https://seamless.ai/b/aaf-logistics-inc-147131241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:49:44,733 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:49:44,779 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:49:44,780 - INFO - Processing document logistics\n",
      "2025-11-17 17:49:44,830 - INFO - Finished converting document logistics in 0.25 sec.\n",
      "2025-11-17 17:49:57,089 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:49:57,093 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:49:57,094 - INFO - Processing document aaf-logistics-llc-usdot-3746208\n",
      "2025-11-17 17:49:57,095 - INFO - Finished converting document aaf-logistics-llc-usdot-3746208 in 0.92 sec.\n",
      "2025-11-17 17:50:06,815 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:50:06,822 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:50:06,822 - INFO - Processing document 3425130\n",
      "2025-11-17 17:50:06,822 - INFO - Finished converting document 3425130 in 1.05 sec.\n",
      "2025-11-17 17:50:20,878 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:50:20,887 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:50:20,888 - INFO - Processing document aaf-logistics-llc\n",
      "2025-11-17 17:50:20,889 - INFO - Finished converting document aaf-logistics-llc in 0.06 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.buzzfile.com/business/AAF-Logistics-LLC-405-924-7957: 403 Client Error: Forbidden for url: https://www.buzzfile.com/business/AAF-Logistics-LLC-405-924-7957\n",
      "[SCRAPER] HTTP 403 for https://www.buzzfile.com/business/AAF-Logistics-LLC-405-924-7957, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:51:03,871 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:51:03,875 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:51:03,876 - INFO - Processing document alvin-fabre-7ab66b1a9\n",
      "2025-11-17 17:51:03,877 - INFO - Finished converting document alvin-fabre-7ab66b1a9 in 0.88 sec.\n",
      "2025-11-17 17:51:19,659 - INFO - detected formats: [<InputFormat.XML_USPTO: 'xml_uspto'>]\n",
      "2025-11-17 17:51:19,659 - ERROR - Input document query.asp with format None does not match any allowed format: (dict_keys([<InputFormat.DOCX: 'docx'>, <InputFormat.PPTX: 'pptx'>, <InputFormat.HTML: 'html'>, <InputFormat.IMAGE: 'image'>, <InputFormat.PDF: 'pdf'>, <InputFormat.ASCIIDOC: 'asciidoc'>, <InputFormat.MD: 'md'>, <InputFormat.CSV: 'csv'>, <InputFormat.XLSX: 'xlsx'>, <InputFormat.XML_USPTO: 'xml_uspto'>, <InputFormat.XML_JATS: 'xml_jats'>, <InputFormat.METS_GBS: 'mets_gbs'>, <InputFormat.JSON_DOCLING: 'json_docling'>, <InputFormat.AUDIO: 'audio'>, <InputFormat.VTT: 'vtt'>]))\n",
      "2025-11-17 17:51:19,659 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130: File format not allowed: query.asp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:51:48,054 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:51:48,069 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:51:48,070 - INFO - Processing document aaf-logistics-llc\n",
      "2025-11-17 17:51:48,084 - INFO - Finished converting document aaf-logistics-llc in 0.78 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://npidb.org/organizations/nursing_service/home-health_163wh0200x/1518848704.aspx: 403 Client Error: Forbidden for url: https://npidb.org/organizations/nursing_service/home-health_163wh0200x/1518848704.aspx\n",
      "[SCRAPER] HTTP 403 for https://npidb.org/organizations/nursing_service/home-health_163wh0200x/1518848704.aspx, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:52:33,524 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:52:33,545 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:52:33,551 - INFO - Processing document privacy-policy\n",
      "2025-11-17 17:52:33,575 - INFO - Finished converting document privacy-policy in 0.12 sec.\n",
      "2025-11-17 17:52:50,865 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:52:50,896 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:52:50,897 - INFO - Processing document services\n",
      "2025-11-17 17:52:50,919 - INFO - Finished converting document services in 0.14 sec.\n",
      "2025-11-17 17:53:05,960 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:53:05,975 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:53:05,975 - INFO - Processing document 61583722310879\n",
      "2025-11-17 17:53:05,980 - INFO - Finished converting document 61583722310879 in 0.78 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/61583722310879/: 400 Client Error: Bad Request for url: https://www.facebook.com/61583722310879/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:53:22,746 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:53:22,789 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:53:22,789 - INFO - Processing document file\n",
      "2025-11-17 17:53:22,845 - INFO - Finished converting document file in 0.20 sec.\n",
      "2025-11-17 17:53:41,639 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:53:41,653 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:53:41,653 - INFO - Processing document able-path-care-staffing-llc-791324234\n",
      "2025-11-17 17:53:41,676 - INFO - Finished converting document able-path-care-staffing-llc-791324234 in 1.38 sec.\n",
      "2025-11-17 17:54:00,324 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:54:00,395 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:54:00,395 - INFO - Processing document ablecarecompany\n",
      "2025-11-17 17:54:00,451 - INFO - Finished converting document ablecarecompany in 1.11 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://providerwire.com/home-health-registered-nurse/georgia/atlanta/able-path-care-staffing-llc-1518848704: 403 Client Error: Forbidden for url: https://providerwire.com/home-health-registered-nurse/georgia/atlanta/able-path-care-staffing-llc-1518848704\n",
      "[SCRAPER] HTTP 403 for https://providerwire.com/home-health-registered-nurse/georgia/atlanta/able-path-care-staffing-llc-1518848704, skipping.\n",
      "[SCRAPER] Docling failed for https://npiprofile.com/npi/1518848704: 403 Client Error: Forbidden for url: https://npiprofile.com/npi/1518848704\n",
      "[SCRAPER] HTTP 403 for https://npiprofile.com/npi/1518848704, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:54:52,916 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:54:52,916 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:54:52,916 - INFO - Processing document able-path-care-staffing-llc-b39196679\n",
      "2025-11-17 17:54:52,932 - INFO - Finished converting document able-path-care-staffing-llc-b39196679 in 1.38 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://npir.org/providers/nursing-providers/163wh0200x/p4a75s: 403 Client Error: Forbidden for url: https://npir.org/providers/nursing-providers/163wh0200x/p4a75s\n",
      "[SCRAPER] HTTP 403 for https://npir.org/providers/nursing-providers/163wh0200x/p4a75s, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 17:55:24,093 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:55:24,118 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:55:24,119 - INFO - Processing document file\n",
      "2025-11-17 17:55:24,162 - INFO - Finished converting document file in 0.20 sec.\n",
      "2025-11-17 17:55:30,589 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:55:30,646 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:55:30,647 - INFO - Processing document accurisk-solutions\n",
      "2025-11-17 17:55:30,674 - INFO - Finished converting document accurisk-solutions in 0.64 sec.\n",
      "2025-11-17 17:55:37,689 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:55:37,696 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:55:37,696 - INFO - Processing document aci-engineering-llc\n",
      "2025-11-17 17:55:37,717 - INFO - Finished converting document aci-engineering-llc in 0.31 sec.\n",
      "2025-11-17 17:56:03,632 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:56:03,648 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:56:03,648 - INFO - Processing document ig37-lp\n",
      "2025-11-17 17:56:03,665 - INFO - Finished converting document ig37-lp in 0.31 sec.\n",
      "2025-11-17 17:56:30,486 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:56:30,519 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:56:30,520 - INFO - Processing document file\n",
      "2025-11-17 17:56:30,557 - INFO - Finished converting document file in 1.73 sec.\n",
      "2025-11-17 17:56:41,445 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:56:41,454 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:56:41,455 - INFO - Processing document adams-site-works-llc.html\n",
      "2025-11-17 17:56:41,499 - INFO - Finished converting document adams-site-works-llc.html in 1.23 sec.\n",
      "2025-11-17 17:56:48,006 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:56:48,019 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:56:48,020 - INFO - Processing document adams-site-works-llc\n",
      "2025-11-17 17:56:48,038 - INFO - Finished converting document adams-site-works-llc in 0.44 sec.\n",
      "2025-11-17 17:57:08,335 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:57:08,344 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:57:08,345 - INFO - Processing document site-work\n",
      "2025-11-17 17:57:08,359 - INFO - Finished converting document site-work in 2.42 sec.\n",
      "2025-11-17 17:57:26,344 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:57:26,366 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:57:26,367 - INFO - Processing document file\n",
      "2025-11-17 17:57:26,386 - INFO - Finished converting document file in 0.12 sec.\n",
      "2025-11-17 17:57:46,954 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:57:46,982 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:57:46,982 - INFO - Processing document about-us\n",
      "2025-11-17 17:57:47,005 - INFO - Finished converting document about-us in 1.22 sec.\n",
      "2025-11-17 17:58:01,044 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:58:01,056 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:58:01,057 - INFO - Processing document adonais-touch-cleaning-llc.html\n",
      "2025-11-17 17:58:01,419 - INFO - Finished converting document adonais-touch-cleaning-llc.html in 1.59 sec.\n",
      "2025-11-17 17:58:07,586 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:58:07,605 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:58:07,606 - INFO - Processing document gallery\n",
      "2025-11-17 17:58:07,620 - INFO - Finished converting document gallery in 1.22 sec.\n",
      "2025-11-17 17:58:18,710 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 17:58:18,724 - INFO - Going to convert document batch...\n",
      "2025-11-17 17:58:18,724 - INFO - Processing document 61555008185849\n",
      "2025-11-17 17:58:18,724 - INFO - Finished converting document 61555008185849 in 0.73 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/people/Adonai-Prestige-Touch-Cleaning-Services/61555008185849/: 400 Client Error: Bad Request for url: https://www.facebook.com/people/Adonai-Prestige-Touch-Cleaning-Services/61555008185849/\n",
      "{\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"2ClickFit, Inc.\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://twoclickfit.com/privacy/\",\n",
      "      \"primary_confidence\": 0.9,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://twoclickfit.com/privacy/\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The URL contains the company name prominently in the privacy policy.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://2clickfit.com/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL matches the company name and contains relevant information about the company and its founders.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.crunchbase.com/organization/2clickfit\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The snippets provide the legal name, phone number, and email of the company, indicating high relevance.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.formds.com/issuers/2clickfit-inc\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The URL contains the official company name and relevant address and contact information.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.streetinsider.com/SEC+Filings/Form+D+2ClickFit%2C+Inc./25521440.html\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention the company name and state of incorporation, but no address or phone number is provided.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"2ClickFit, Inc.\",\n",
      "          \"source\": \"https://www.crunchbase.com/organization/2clickfit\",\n",
      "          \"confidence\": 0.975,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.crunchbase.com/organization/2clickfit\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"829 Loveland Road\",\n",
      "          \"source\": \"https://www.formds.com/issuers/2clickfit-inc\",\n",
      "          \"confidence\": 0.775,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.formds.com/issuers/2clickfit-inc\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"Moorestown\",\n",
      "          \"source\": \"https://www.formds.com/issuers/2clickfit-inc\",\n",
      "          \"confidence\": 0.775,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.formds.com/issuers/2clickfit-inc\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"NJ\",\n",
      "          \"source\": \"https://www.formds.com/issuers/2clickfit-inc\",\n",
      "          \"confidence\": 0.775,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.formds.com/issuers/2clickfit-inc\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"08057\",\n",
      "          \"source\": \"https://www.formds.com/issuers/2clickfit-inc\",\n",
      "          \"confidence\": 0.775,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.formds.com/issuers/2clickfit-inc\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"value\": \"+1 8567935014\",\n",
      "          \"source\": \"https://www.crunchbase.com/organization/2clickfit\",\n",
      "          \"confidence\": 0.775,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.crunchbase.com/organization/2clickfit\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"529 TECH LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://www.linkedin.com/company/529-technologies\",\n",
      "      \"primary_confidence\": 0.8,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://www.linkedin.com/company/529-technologies\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention '529 Technologies' as the company name and provide relevant industry and website information.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"http://529-tech.com/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL matches the company name closely and appears to be the official site, but no address or phone information is available.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.529store.com/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL matches the company name and is likely the official site, with relevant industry information.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.ascensus.com/solutions/education/529-plans/\",\n",
      "          \"overall_score\": 0.5,\n",
      "          \"reason\": \"The URL is likely the official site for Ascensus, which is relevant to the 529 plans, but does not directly mention Super7 or 529 TECH LLC.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.dnb.com/business-directory/company-information.computer_systems_design_and_related_services.us.washington.renton.html\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention the company name and its location, indicating relevance to the target company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://apps.apple.com/us/app/flyenjoy/id6745104853\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention '529 Tech LLC' as the developer and provide a website link, indicating relevance to the company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://iphone.apkpure.com/app/flyenjoy/com.test.flyenjoy\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippet clearly mentions the company name '529 Tech LLC', but no address or phone information is provided.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"529 Tech LLC\",\n",
      "          \"source\": \"https://apps.apple.com/us/app/flyenjoy/id6745104853\",\n",
      "          \"confidence\": 0.9,\n",
      "          \"all_sources\": [\n",
      "            \"https://apps.apple.com/us/app/flyenjoy/id6745104853\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": null,\n",
      "        \"city\": null,\n",
      "        \"state\": null,\n",
      "        \"country\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"901 Tax Pros LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "      \"primary_confidence\": 1.0,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://901taxprosllc.com/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL matches the company name exactly and appears to be the official site, but no address or phone number was found.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.facebook.com/p/901-Tax-Pros-100095787630640/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The company name matches exactly with high confidence, and the URL appears to be an official Facebook page.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains the official registration details for 901 Tax Pros LLC, including the name, address, and other relevant information.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"901 Tax Pros LLC\",\n",
      "          \"source\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"confidence\": 1.0,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"124 Center St NW Unit 105\",\n",
      "          \"source\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"Atlanta\",\n",
      "          \"source\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"GA\",\n",
      "          \"source\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"30313\",\n",
      "          \"source\": \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.georgiacompanyregistry.com/companies/901-tax-pros-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"A2 Exteriors LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://a2details.co/services/\",\n",
      "      \"primary_confidence\": 1.0,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://a2details.co/services/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains relevant information about A2 Exteriors LLC, including the company name, address, phone number, and is likely the official site.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://pcn.procore.com/p/a2-weatherproofing-llc-springfield\",\n",
      "          \"overall_score\": 0.85,\n",
      "          \"reason\": \"The URL contains relevant information about A2 Exteriors LLC, including the address and matches the company name.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.facebook.com/groups/864305987876251/posts/1480557592917751/\",\n",
      "          \"overall_score\": 0.5,\n",
      "          \"reason\": \"The company name is clearly mentioned, and the city is identified, but no address or phone number is provided.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.facebook.com/groups/864305987876251/\",\n",
      "          \"overall_score\": 0.5,\n",
      "          \"reason\": \"The snippets mention the company name and city, but no address or phone number is provided.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.facebook.com/groups/1364647736883680/posts/7762970760384647/\",\n",
      "          \"overall_score\": 0.5,\n",
      "          \"reason\": \"The company name is explicitly mentioned, and the city is inferred from the context, but no address or phone number is provided.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.thumbtack.com/ct/norwich/pressure-washing\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippet mentions A2 Exteriors LLC directly, indicating a strong relevance to the company.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"A2 Exteriors LLC\",\n",
      "          \"source\": \"https://pcn.procore.com/p/a2-weatherproofing-llc-springfield\",\n",
      "          \"confidence\": 0.9125,\n",
      "          \"all_sources\": [\n",
      "            \"https://pcn.procore.com/p/a2-weatherproofing-llc-springfield\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"903 Ann Arbor Road\",\n",
      "          \"source\": \"https://maps.app.goo.gl/PhcPcQsipDsvSKMt6\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://maps.app.goo.gl/PhcPcQsipDsvSKMt6\",\n",
      "            \"https://a2details.co/services/\",\n",
      "            \"https://www.google.com/maps/dir//903+Ann+Arbor+Rd,+Plymouth,+MI+48170\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"Plymouth\",\n",
      "          \"source\": \"https://a2details.co/services/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://a2details.co/services/\",\n",
      "            \"https://www.google.com/maps/dir//903+Ann+Arbor+Rd,+Plymouth,+MI+48170\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"MI\",\n",
      "          \"source\": \"https://a2details.co/services/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://a2details.co/services/\",\n",
      "            \"https://www.google.com/maps/dir//903+Ann+Arbor+Rd,+Plymouth,+MI+48170\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"48170\",\n",
      "          \"source\": \"https://a2details.co/services/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://a2details.co/services/\",\n",
      "            \"https://www.google.com/maps/dir//903+Ann+Arbor+Rd,+Plymouth,+MI+48170\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"value\": \"734-377-8764\",\n",
      "          \"source\": \"https://a2details.co/services/\",\n",
      "          \"confidence\": 0.75,\n",
      "          \"all_sources\": [\n",
      "            \"https://a2details.co/services/\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"AAF Logistics LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://searchcarriers.com/company/3425130\",\n",
      "      \"primary_confidence\": 1.0,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://www.zoominfo.com/c/aaf-logistics-inc/346190257\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The company name matches closely with the target company, and the website is likely official.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://seamless.ai/b/aaf-logistics-inc-147131241\",\n",
      "          \"overall_score\": 0.85,\n",
      "          \"reason\": \"The snippets provide clear and relevant information about Aaf Logistics Inc., including its name, address, phone number, industry, and website.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.aafintl.com/us/industries/logistics\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The URL directly references AAF Logistics LLC, indicating a strong relevance to the company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://searchcarriers.com/company/3425130\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The snippets directly mention the company name and DOT number, indicating a strong relevance to the target company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://carriernetwork.ai/carrier-profile/3746208/aaf-logistics-llc\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The URL contains detailed information about Aaf Logistics LLC, including its name, address, and identifiers, indicating it is a relevant and likely official profile.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.buzzfile.com/business/AAF-Logistics-LLC-405-924-7957\",\n",
      "          \"overall_score\": 0.9,\n",
      "          \"reason\": \"The URL directly corresponds to the company AAF Logistics LLC, with clear identification of the company name and industry.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.linkedin.com/in/alvin-fabre-7ab66b1a9\",\n",
      "          \"overall_score\": 0.6,\n",
      "          \"reason\": \"The snippets clearly mention the company name and city, but no address or phone information is provided.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL provides a complete snapshot of AAF Logistics LLC, including its name, address, phone number, and DOT number, indicating it is a relevant and official source.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.bizprofile.net/ca/san-diego/aaf-logistics-llc\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains comprehensive and accurate information about Aaf Logistics LLC, including its name, address, registration ID, and industry.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"AAF Logistics LLC\",\n",
      "          \"source\": \"https://searchcarriers.com/company/3425130\",\n",
      "          \"confidence\": 1.0,\n",
      "          \"all_sources\": [\n",
      "            \"https://searchcarriers.com/company/3425130\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"3317 SE 15TH ST\",\n",
      "          \"source\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"DEL CITY\",\n",
      "          \"source\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"OK\",\n",
      "          \"source\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"73115\",\n",
      "          \"source\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"value\": \"(405) 924-7956\",\n",
      "          \"source\": \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=3425130\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"Able Path Care & Staffing LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "      \"primary_confidence\": 1.0,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://npidb.org/organizations/nursing_service/home-health_163wh0200x/1518848704.aspx\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention the company name and director, with a high match score for the name.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains relevant information about Able Path Care & Staffing LLC, including contact details and address, indicating it is likely the official site.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://ablepathcare.com/services/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains relevant information about Able Path Care & Staffing LLC, including contact details and address.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.facebook.com/61583722310879/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The company name matches exactly with the provided input, and the URL is a social media profile likely representing the company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://ablepathcare.com/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL matches the company name and contains relevant contact information.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.mapquest.com/us/georgia/able-path-care-staffing-llc-791324234\",\n",
      "          \"overall_score\": 0.95,\n",
      "          \"reason\": \"The URL contains the exact company name and relevant address and phone number, indicating it is likely the official site.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.linkedin.com/company/ablecarecompany\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL is the official LinkedIn page for Able Care, and relevant address details were extracted from the snippets.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://providerwire.com/home-health-registered-nurse/georgia/atlanta/able-path-care-staffing-llc-1518848704\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL contains the exact company name and relevant location information, indicating a strong match.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://npiprofile.com/npi/1518848704\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains the official NPI profile for Able Path Care & Staffing LLC, with complete and matching details.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://npir.org/providers/nursing-providers/163wh0200x/p4a75s\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention the company name and its location, indicating relevance.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"Able Path Care & Staffing LLC\",\n",
      "          \"source\": \"https://www.mapquest.com/us/georgia/able-path-care-staffing-llc-791324234\",\n",
      "          \"confidence\": 0.9875,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.mapquest.com/us/georgia/able-path-care-staffing-llc-791324234\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"1175 Peachtree St. NE Suite 1000\",\n",
      "          \"source\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://ablepathcare.com/privacy-policy/\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"Atlanta\",\n",
      "          \"source\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://ablepathcare.com/privacy-policy/\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"GA\",\n",
      "          \"source\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://ablepathcare.com/privacy-policy/\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"30361\",\n",
      "          \"source\": \"https://ablepathcare.com/privacy-policy/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://ablepathcare.com/privacy-policy/\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"value\": \"678-201-1772\",\n",
      "          \"source\": \"https://ablepathcare.com/services/\",\n",
      "          \"confidence\": 0.7999999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://ablepathcare.com/services/\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"Acirdek Solutions LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "      \"primary_confidence\": 0.7,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippets contain relevant information about Acirdek Solutions LLC, including its address and tax ID, but the URL does not appear to be the official site.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://texas-biz.com/co/ig37-lp\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippets contain relevant information about Acirdek Solutions LLC, including its address and tax ID, but the website is not official.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"Acirdek Solutions LLC\",\n",
      "          \"source\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"confidence\": 0.725,\n",
      "          \"all_sources\": [\n",
      "            \"https://texas-biz.com/co/aci-engineering-llc\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"781 COUNTRY PLACE DR APT 2032\",\n",
      "          \"source\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"confidence\": 0.5249999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://texas-biz.com/co/aci-engineering-llc\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"HOUSTON\",\n",
      "          \"source\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"confidence\": 0.5249999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://texas-biz.com/co/aci-engineering-llc\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"TX\",\n",
      "          \"source\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"confidence\": 0.5249999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://texas-biz.com/co/aci-engineering-llc\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"77079\",\n",
      "          \"source\": \"https://texas-biz.com/co/aci-engineering-llc\",\n",
      "          \"confidence\": 0.5249999999999999,\n",
      "          \"all_sources\": [\n",
      "            \"https://texas-biz.com/co/aci-engineering-llc\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": null\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"Adams Site Works, LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "      \"primary_confidence\": 1.0,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://adamsaai.com/\",\n",
      "          \"overall_score\": 0.0,\n",
      "          \"reason\": \"No relevant entities found for Super7; the snippets focus on Adams Site Works, LLC.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"overall_score\": 1.0,\n",
      "          \"reason\": \"The URL contains complete and accurate information about the company, including its name, address, and registration ID.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://adamslandworx.com/service/site-work/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The snippets clearly mention the company name and its services, indicating relevance to the target company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://search.sunbiz.org/Inquiry/CorporationSearch/SearchResults?inquiryType=EntityName&inquiryDirectionType=CurrentList&searchTerm=ADAMS%20PROFESSIONAL%20COUNSELING%20SERVICES%2C%20INC.&searchNameOrder=ADAMSSHOEREPAIR%20P090000079960&ListNameOrder=ADAMSSHOEREPAIR%20P090000079960\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The company name matches closely with the target company, but no address or phone information is available.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://adamscontractingky.com/\",\n",
      "          \"overall_score\": 0.8,\n",
      "          \"reason\": \"The URL matches the company name and contains relevant contact information.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"ADAMS SITE WORKS, LLC\",\n",
      "          \"source\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"confidence\": 1.0,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": {\n",
      "          \"value\": \"29919 SE 152ND PL\",\n",
      "          \"source\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"city\": {\n",
      "          \"value\": \"ALTOONA\",\n",
      "          \"source\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"state\": {\n",
      "          \"value\": \"FL\",\n",
      "          \"source\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"country\": null,\n",
      "        \"zip\": {\n",
      "          \"value\": \"32702\",\n",
      "          \"source\": \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\",\n",
      "          \"confidence\": 0.85,\n",
      "          \"all_sources\": [\n",
      "            \"https://www.flcompanyregistry.com/companies/adams-site-works-llc/\"\n",
      "          ]\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"value\": \"(859) 629-4948\",\n",
      "          \"source\": \"https://adamscontractingky.com/\",\n",
      "          \"confidence\": 0.7000000000000001,\n",
      "          \"all_sources\": [\n",
      "            \"https://adamscontractingky.com/\"\n",
      "          ]\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"input\": {\n",
      "        \"company_name\": \"Adonai's Touch Cleaning LLC\",\n",
      "        \"country\": null,\n",
      "        \"state\": null,\n",
      "        \"city\": null,\n",
      "        \"street_address\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      },\n",
      "      \"primary_url\": \"https://adonaiscleaningservices.com/about-us/\",\n",
      "      \"primary_confidence\": 0.7,\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"url\": \"https://adonaiscleaningservices.com/about-us/\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippets clearly mention the company name and its location, indicating relevance to the target company.\"\n",
      "        },\n",
      "        {\n",
      "          \"url\": \"https://adonaiscleaningservices.com/gallery/\",\n",
      "          \"overall_score\": 0.7,\n",
      "          \"reason\": \"The snippets clearly mention the company name and provide a link to the official website.\"\n",
      "        }\n",
      "      ],\n",
      "      \"super7_summary\": {\n",
      "        \"company_name\": {\n",
      "          \"value\": \"Adonai's Cleaning Services LLC\",\n",
      "          \"source\": \"https://adonaiscleaningservices.com/about-us/\",\n",
      "          \"confidence\": 0.725,\n",
      "          \"all_sources\": [\n",
      "            \"https://adonaiscleaningservices.com/about-us/\"\n",
      "          ]\n",
      "        },\n",
      "        \"street_address\": null,\n",
      "        \"city\": null,\n",
      "        \"state\": null,\n",
      "        \"country\": null,\n",
      "        \"zip\": null,\n",
      "        \"phone\": null\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_input_noaddress = [\n",
    "    {\n",
    "        \"company_name\": \"2ClickFit, Inc.\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"529 TECH LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"901 Tax Pros LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"A2 Exteriors LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"AAF Logistics LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Able Path Care & Staffing LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Acirdek Solutions LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Adams Site Works, LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Adonai's Touch Cleaning LLC\"\n",
    "    }\n",
    "]\n",
    "\n",
    "res = resolve_super7_batch(batch_input_noaddress)\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e30a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b2bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_input_address_found = [\n",
    "#     {\n",
    "#         \"company_name\": \"ELITE CAPITAL OPTIMIZATION LLC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"JET COAST CARRIERS LLC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"R&K FIRE SUPPORT LLC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"Home Fit Solutions LLC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"CHRISTINE TUFTS BCBA INC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"Beacon Retirement Strategies\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"DAVID'S TIRE SHOP\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"The Leverage Line Group LLC\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"Raquel's Tax Service\"\n",
    "#     },\n",
    "#     {\n",
    "#         \"company_name\": \"1KG Da Label\"\n",
    "#     }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8ef310",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_address_found = [\n",
    "    {\n",
    "        \"company_name\": \"ELITE CAPITAL OPTIMIZATION LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"JET COAST CARRIERS LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"R&K FIRE SUPPORT LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Home Fit Solutions LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"CHRISTINE TUFTS BCBA INC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Beacon Retirement Strategies\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"DAVID'S TIRE SHOP\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"The Leverage Line Group LLC\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"Raquel's Tax Service\"\n",
    "    },\n",
    "    {\n",
    "        \"company_name\": \"1KG Da Label\"\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89999578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:00:09,364 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:00:09,377 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:00:09,378 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-11-17 18:00:09,378 - INFO - Processing document elite-capital-optimization-llc\n",
      "2025-11-17 18:00:09,386 - INFO - Finished converting document elite-capital-optimization-llc in 0.73 sec.\n",
      "2025-11-17 18:00:24,161 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:00:24,211 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:00:24,212 - INFO - Processing document index.html\n",
      "2025-11-17 18:00:24,223 - WARNING - Clashing hyperlinks: 'https://outlook.office.com/book/EliteCapitalInsuranceServices@NETORG17124433.onmicrosoft.com/' and 'https://thefinancialhq.com/elitecapitalandinsuranceservices'! Chose 'https://thefinancialhq.com/elitecapitalandinsuranceservices'\n",
      "2025-11-17 18:00:24,266 - INFO - Finished converting document index.html in 1.27 sec.\n",
      "2025-11-17 18:00:43,425 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:00:43,447 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:00:43,447 - INFO - Processing document file\n",
      "2025-11-17 18:00:43,467 - INFO - Finished converting document file in 0.36 sec.\n",
      "2025-11-17 18:01:03,517 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:01:03,522 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:01:03,522 - INFO - Processing document file\n",
      "2025-11-17 18:01:03,540 - INFO - Finished converting document file in 1.38 sec.\n",
      "2025-11-17 18:01:24,229 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:01:24,245 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:01:24,246 - INFO - Processing document file\n",
      "2025-11-17 18:01:24,259 - INFO - Finished converting document file in 0.11 sec.\n",
      "2025-11-17 18:01:40,702 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:01:40,765 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:01:40,766 - INFO - Processing document eliteoptimization\n",
      "2025-11-17 18:01:40,803 - INFO - Finished converting document eliteoptimization in 0.88 sec.\n",
      "2025-11-17 18:01:53,124 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:01:53,124 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:01:53,124 - INFO - Processing document 145449\n",
      "2025-11-17 18:01:53,124 - INFO - Finished converting document 145449 in 1.16 sec.\n",
      "2025-11-17 18:02:03,668 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:02:03,703 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:02:03,707 - INFO - Processing document file\n",
      "2025-11-17 18:02:03,759 - INFO - Finished converting document file in 0.17 sec.\n",
      "2025-11-17 18:02:20,630 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:02:20,677 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:02:20,678 - INFO - Processing document 55\n",
      "2025-11-17 18:02:20,743 - INFO - Finished converting document 55 in 0.88 sec.\n",
      "2025-11-17 18:02:36,546 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:02:36,559 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:02:36,560 - INFO - Processing document a-and-z-consulting\n",
      "2025-11-17 18:02:36,566 - INFO - Finished converting document a-and-z-consulting in 0.75 sec.\n",
      "2025-11-17 18:03:15,637 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:03:15,655 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:03:15,655 - INFO - Processing document 4454012\n",
      "2025-11-17 18:03:15,681 - INFO - Finished converting document 4454012 in 0.22 sec.\n",
      "2025-11-17 18:03:33,581 - INFO - detected formats: [<InputFormat.XML_USPTO: 'xml_uspto'>]\n",
      "2025-11-17 18:03:33,582 - ERROR - Input document query.asp with format None does not match any allowed format: (dict_keys([<InputFormat.DOCX: 'docx'>, <InputFormat.PPTX: 'pptx'>, <InputFormat.HTML: 'html'>, <InputFormat.IMAGE: 'image'>, <InputFormat.PDF: 'pdf'>, <InputFormat.ASCIIDOC: 'asciidoc'>, <InputFormat.MD: 'md'>, <InputFormat.CSV: 'csv'>, <InputFormat.XLSX: 'xlsx'>, <InputFormat.XML_USPTO: 'xml_uspto'>, <InputFormat.XML_JATS: 'xml_jats'>, <InputFormat.METS_GBS: 'mets_gbs'>, <InputFormat.JSON_DOCLING: 'json_docling'>, <InputFormat.AUDIO: 'audio'>, <InputFormat.VTT: 'vtt'>]))\n",
      "2025-11-17 18:03:33,583 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=4454012: File format not allowed: query.asp\n",
      "[SCRAPER] Docling failed for https://www.carriersource.io/carriers/jet-trucking-llc-1552502: 403 Client Error: Forbidden for url: https://www.carriersource.io/carriers/jet-trucking-llc-1552502\n",
      "[SCRAPER] HTTP 403 for https://www.carriersource.io/carriers/jet-trucking-llc-1552502, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:04:18,879 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:04:18,888 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:04:18,888 - INFO - Processing document USDOT-4454012\n",
      "2025-11-17 18:04:18,902 - INFO - Finished converting document USDOT-4454012 in 0.92 sec.\n",
      "2025-11-17 18:04:48,168 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:04:48,179 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:04:48,179 - INFO - Processing document jet-coast-carriers-llc\n",
      "2025-11-17 18:04:48,196 - INFO - Finished converting document jet-coast-carriers-llc in 0.52 sec.\n",
      "2025-11-17 18:05:03,525 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:05:03,532 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:05:03,532 - INFO - Processing document ebonie-whigham-2bb970383\n",
      "2025-11-17 18:05:03,533 - INFO - Finished converting document ebonie-whigham-2bb970383 in 0.62 sec.\n",
      "2025-11-17 18:05:25,790 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:05:25,798 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:05:25,798 - INFO - Processing document jet-coast-carriers-llc.html\n",
      "2025-11-17 18:05:25,844 - INFO - Finished converting document jet-coast-carriers-llc.html in 1.23 sec.\n",
      "2025-11-17 18:05:33,010 - INFO - detected formats: [<InputFormat.XML_USPTO: 'xml_uspto'>]\n",
      "2025-11-17 18:05:33,010 - ERROR - Input document keywordx.asp with format None does not match any allowed format: (dict_keys([<InputFormat.DOCX: 'docx'>, <InputFormat.PPTX: 'pptx'>, <InputFormat.HTML: 'html'>, <InputFormat.IMAGE: 'image'>, <InputFormat.PDF: 'pdf'>, <InputFormat.ASCIIDOC: 'asciidoc'>, <InputFormat.MD: 'md'>, <InputFormat.CSV: 'csv'>, <InputFormat.XLSX: 'xlsx'>, <InputFormat.XML_USPTO: 'xml_uspto'>, <InputFormat.XML_JATS: 'xml_jats'>, <InputFormat.METS_GBS: 'mets_gbs'>, <InputFormat.JSON_DOCLING: 'json_docling'>, <InputFormat.AUDIO: 'audio'>, <InputFormat.VTT: 'vtt'>]))\n",
      "2025-11-17 18:05:33,010 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://safer.fmcsa.dot.gov/keywordx.asp?searchstring=*JET*: File format not allowed: keywordx.asp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:05:57,009 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:05:57,030 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:05:57,031 - INFO - Processing document file\n",
      "2025-11-17 18:05:57,055 - INFO - Finished converting document file in 0.14 sec.\n",
      "2025-11-17 18:06:11,224 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:06:11,236 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:06:11,237 - INFO - Processing document USDOT-4453185\n",
      "2025-11-17 18:06:11,252 - INFO - Finished converting document USDOT-4453185 in 1.02 sec.\n",
      "2025-11-17 18:06:31,917 - INFO - detected formats: [<InputFormat.XML_USPTO: 'xml_uspto'>]\n",
      "2025-11-17 18:06:31,918 - ERROR - Input document query.asp with format None does not match any allowed format: (dict_keys([<InputFormat.DOCX: 'docx'>, <InputFormat.PPTX: 'pptx'>, <InputFormat.HTML: 'html'>, <InputFormat.IMAGE: 'image'>, <InputFormat.PDF: 'pdf'>, <InputFormat.ASCIIDOC: 'asciidoc'>, <InputFormat.MD: 'md'>, <InputFormat.CSV: 'csv'>, <InputFormat.XLSX: 'xlsx'>, <InputFormat.XML_USPTO: 'xml_uspto'>, <InputFormat.XML_JATS: 'xml_jats'>, <InputFormat.METS_GBS: 'mets_gbs'>, <InputFormat.JSON_DOCLING: 'json_docling'>, <InputFormat.AUDIO: 'audio'>, <InputFormat.VTT: 'vtt'>]))\n",
      "2025-11-17 18:06:31,918 - INFO - Going to convert document batch...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://safer.fmcsa.dot.gov/query.asp?searchtype=ANY&query_type=queryCarrierSnapshot&query_param=USDOT&query_string=4453185: File format not allowed: query.asp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:07:12,976 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:07:12,984 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:07:12,984 - INFO - Processing document homefitsolutionsllc\n",
      "2025-11-17 18:07:12,984 - INFO - Finished converting document homefitsolutionsllc in 0.53 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/homefitsolutionsllc/: 400 Client Error: Bad Request for url: https://www.facebook.com/homefitsolutionsllc/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:07:27,993 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:07:28,005 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:07:28,005 - INFO - Processing document contact\n",
      "2025-11-17 18:07:28,021 - INFO - Finished converting document contact in 0.67 sec.\n",
      "2025-11-17 18:07:45,712 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:07:45,726 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:07:45,726 - INFO - Processing document home\n",
      "2025-11-17 18:07:45,742 - INFO - Finished converting document home in 0.06 sec.\n",
      "2025-11-17 18:07:57,427 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:07:57,439 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:07:57,439 - INFO - Processing document file\n",
      "2025-11-17 18:07:57,448 - INFO - Finished converting document file in 0.06 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.mapquest.com/us/florida/fit-home-solutions-llc-423891415: 404 Client Error: Not Found for url: https://www.mapquest.com/us/florida/fit-home-solutions-llc-423891415\n",
      "[SCRAPER] HTTP error 404 for https://www.mapquest.com/us/florida/fit-home-solutions-llc-423891415: 404 Client Error: Not Found for url: https://www.mapquest.com/us/florida/fit-home-solutions-llc-423891415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:08:46,772 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:08:46,788 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:08:46,788 - INFO - Processing document CwsObiNujNy\n",
      "2025-11-17 18:08:46,788 - INFO - Finished converting document CwsObiNujNy in 1.48 sec.\n",
      "2025-11-17 18:08:59,195 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:08:59,209 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:08:59,209 - INFO - Processing document christine-tufts-bcba-inc-400800162\n",
      "2025-11-17 18:08:59,228 - INFO - Finished converting document christine-tufts-bcba-inc-400800162 in 0.44 sec.\n",
      "2025-11-17 18:09:49,672 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:09:49,694 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:09:49,695 - INFO - Processing document christine-tufts-bcba-inc\n",
      "2025-11-17 18:09:49,725 - INFO - Finished converting document christine-tufts-bcba-inc in 0.38 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://clustrmaps.com/person/Tufts-9l5s1t: 403 Client Error: Forbidden for url: https://clustrmaps.com/person/Tufts-9l5s1t\n",
      "[SCRAPER] HTTP 403 for https://clustrmaps.com/person/Tufts-9l5s1t, skipping.\n",
      "[SCRAPER] Docling failed for https://clustrmaps.com/person/Sweany-a3c4h6: 403 Client Error: Forbidden for url: https://clustrmaps.com/person/Sweany-a3c4h6\n",
      "[SCRAPER] HTTP 403 for https://clustrmaps.com/person/Sweany-a3c4h6, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:10:38,677 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:10:38,702 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:10:38,704 - INFO - Processing document file\n",
      "2025-11-17 18:10:38,739 - INFO - Finished converting document file in 1.01 sec.\n",
      "2025-11-17 18:10:56,614 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:10:56,628 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:10:56,629 - INFO - Processing document useful-links\n",
      "2025-11-17 18:10:56,650 - INFO - Finished converting document useful-links in 1.03 sec.\n",
      "2025-11-17 18:11:19,401 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:11:19,421 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:11:19,422 - INFO - Processing document tv-and-radio\n",
      "2025-11-17 18:11:19,446 - INFO - Finished converting document tv-and-radio in 0.14 sec.\n",
      "2025-11-17 18:11:30,678 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:11:30,705 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:11:30,705 - INFO - Processing document social-security\n",
      "2025-11-17 18:11:30,747 - INFO - Finished converting document social-security in 0.34 sec.\n",
      "2025-11-17 18:11:43,847 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:11:43,875 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:11:43,876 - INFO - Processing document file\n",
      "2025-11-17 18:11:43,903 - INFO - Finished converting document file in 0.30 sec.\n",
      "2025-11-17 18:12:00,858 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:12:00,881 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:12:00,882 - INFO - Processing document file\n",
      "2025-11-17 18:12:00,909 - INFO - Finished converting document file in 2.20 sec.\n",
      "2025-11-17 18:12:21,890 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:12:21,916 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:12:21,917 - INFO - Processing document watch\n",
      "2025-11-17 18:12:21,918 - INFO - Finished converting document watch in 1.30 sec.\n",
      "2025-11-17 18:12:27,593 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:12:27,596 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:12:27,597 - INFO - Processing document beacon-retirement-strategies\n",
      "2025-11-17 18:12:27,599 - INFO - Finished converting document beacon-retirement-strategies in 0.27 sec.\n",
      "2025-11-17 18:12:35,803 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:12:35,820 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:12:35,821 - INFO - Processing document beaconcm\n",
      "2025-11-17 18:12:35,845 - INFO - Finished converting document beaconcm in 0.55 sec.\n",
      "2025-11-17 18:12:47,024 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:12:47,076 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:12:47,077 - INFO - Processing document id1493536679\n",
      "2025-11-17 18:12:47,481 - INFO - Finished converting document id1493536679 in 1.75 sec.\n",
      "2025-11-17 18:13:01,073 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:13:01,089 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:13:01,089 - INFO - Processing document who-we-serve\n",
      "2025-11-17 18:13:01,115 - INFO - Finished converting document who-we-serve in 1.01 sec.\n",
      "2025-11-17 18:13:22,183 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:13:22,204 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:13:22,204 - INFO - Processing document about-us\n",
      "2025-11-17 18:13:22,232 - INFO - Finished converting document about-us in 0.70 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.davidstire.com/: 403 Client Error: Forbidden for url: https://www.davidstire.com/\n",
      "[SCRAPER] HTTP 403 for https://www.davidstire.com/, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:13:48,668 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:13:48,675 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:13:48,675 - INFO - Processing document file\n",
      "2025-11-17 18:13:48,692 - INFO - Finished converting document file in 0.12 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.tirerack.com/installer/InstallerDetail.jsp?ID=6680520-001&srsltid=AfmBOooUv8Jg4H3P_zwGVlhk8OQOcano-VXG-8kuwEG03DdOBOIx8S2v: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "[SCRAPER] Failed https://www.tirerack.com/installer/InstallerDetail.jsp?ID=6680520-001&srsltid=AfmBOooUv8Jg4H3P_zwGVlhk8OQOcano-VXG-8kuwEG03DdOBOIx8S2v: HTTPSConnectionPool(host='www.tirerack.com', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:14:54,951 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:14:54,972 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:14:54,973 - INFO - Processing document davids-tire-shop-264897081\n",
      "2025-11-17 18:14:54,995 - INFO - Finished converting document davids-tire-shop-264897081 in 1.00 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.cityof.com/tx/houston/davids-tire-shop-7253246: 403 Client Error: Forbidden for url: https://www.cityof.com/tx/houston/davids-tire-shop-7253246\n",
      "[SCRAPER] HTTP 403 for https://www.cityof.com/tx/houston/davids-tire-shop-7253246, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:15:38,920 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:15:38,952 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:15:38,954 - INFO - Processing document watch\n",
      "2025-11-17 18:15:38,964 - INFO - Finished converting document watch in 0.92 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] Docling failed for https://www.carfax.com/Reviews-Davids-Tire-Shop-Tampa-FL_B8ETBMTPYH: 403 Client Error: Forbidden for url: https://www.carfax.com/Reviews-Davids-Tire-Shop-Tampa-FL_B8ETBMTPYH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:16:16,571 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:16:16,578 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:16:16,585 - INFO - Processing document DGvPP63xOwS\n",
      "2025-11-17 18:16:16,585 - INFO - Finished converting document DGvPP63xOwS in 0.72 sec.\n",
      "2025-11-17 18:16:27,528 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:16:27,545 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:16:27,546 - INFO - Processing document davids-tire-shop-co.\n",
      "2025-11-17 18:16:27,550 - INFO - Finished converting document davids-tire-shop-co. in 0.73 sec.\n",
      "2025-11-17 18:16:52,889 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:16:52,905 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:16:52,905 - INFO - Processing document TheLeverageLineGroup\n",
      "2025-11-17 18:16:52,914 - INFO - Finished converting document TheLeverageLineGroup in 0.61 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SCRAPER] HTTP error 400 for https://www.facebook.com/TheLeverageLineGroup/: 400 Client Error: Bad Request for url: https://www.facebook.com/TheLeverageLineGroup/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-17 18:17:07,798 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:17:07,819 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:17:07,819 - INFO - Processing document about\n",
      "2025-11-17 18:17:07,836 - INFO - Finished converting document about in 0.53 sec.\n",
      "2025-11-17 18:17:18,680 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:17:18,694 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:17:18,694 - INFO - Processing document contact\n",
      "2025-11-17 18:17:18,711 - INFO - Finished converting document contact in 0.66 sec.\n",
      "2025-11-17 18:17:38,408 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:17:38,424 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:17:38,425 - INFO - Processing document file\n",
      "2025-11-17 18:17:38,438 - INFO - Finished converting document file in 0.55 sec.\n",
      "2025-11-17 18:17:49,921 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:17:49,989 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:17:49,990 - INFO - Processing document file\n",
      "2025-11-17 18:17:50,079 - INFO - Finished converting document file in 2.33 sec.\n",
      "2025-11-17 18:18:04,013 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:18:04,041 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:18:04,046 - INFO - Processing document the-leverage-group-llc\n",
      "2025-11-17 18:18:04,081 - INFO - Finished converting document the-leverage-group-llc in 0.50 sec.\n",
      "2025-11-17 18:18:18,393 - INFO - detected formats: [<InputFormat.HTML: 'html'>]\n",
      "2025-11-17 18:18:18,403 - INFO - Going to convert document batch...\n",
      "2025-11-17 18:18:18,403 - INFO - Processing document THE+LEVERAGE+GROUP%2C+LLC\n",
      "2025-11-17 18:18:18,409 - INFO - Finished converting document THE+LEVERAGE+GROUP%2C+LLC in 0.34 sec.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m res2 = \u001b[43mresolve_super7_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_input_address_found\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(res, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1041\u001b[39m, in \u001b[36mresolve_super7_batch\u001b[39m\u001b[34m(super7_payloads)\u001b[39m\n\u001b[32m   1039\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m payload \u001b[38;5;129;01min\u001b[39;00m super7_payloads:\n\u001b[32m   1040\u001b[39m     s7 = Super7Input(**payload)\n\u001b[32m-> \u001b[39m\u001b[32m1041\u001b[39m     out = \u001b[43mresolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_company\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms7\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1042\u001b[39m     results.append(out)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m: results}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 989\u001b[39m, in \u001b[36mSuper7Resolver.process_company\u001b[39m\u001b[34m(self, s7)\u001b[39m\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    988\u001b[39m \u001b[38;5;66;03m# 5) LLM extraction on snippets\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m989\u001b[39m extraction = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_from_snippets\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms7\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    990\u001b[39m candidate_records.append(\n\u001b[32m    991\u001b[39m     CandidateRecord(\n\u001b[32m    992\u001b[39m         url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    995\u001b[39m     )\n\u001b[32m    996\u001b[39m )\n\u001b[32m    998\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m extraction.overall_score > primary_conf:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 771\u001b[39m, in \u001b[36mLLMExtractor.extract_from_snippets\u001b[39m\u001b[34m(self, s7, url, snippets)\u001b[39m\n\u001b[32m    755\u001b[39m         confidence = \u001b[32m0.0\u001b[39m\n\u001b[32m    757\u001b[39m     ents.append(\n\u001b[32m    758\u001b[39m         ExtractedEntity(\n\u001b[32m    759\u001b[39m             entity_type=entity_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    763\u001b[39m         )\n\u001b[32m    764\u001b[39m     )\n\u001b[32m    766\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PageExtractionResult(\n\u001b[32m    767\u001b[39m     url=url_out,\n\u001b[32m    768\u001b[39m     entities=ents,\n\u001b[32m    769\u001b[39m     match_score_name=\u001b[38;5;28mfloat\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mmatch_score_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    770\u001b[39m     match_score_address=\u001b[38;5;28mfloat\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mmatch_score_address\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m     match_score_phone=\u001b[38;5;28mfloat\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mmatch_score_phone\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    772\u001b[39m     looks_like_official_site=\u001b[38;5;28mbool\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mlooks_like_official_site\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[32m    773\u001b[39m     overall_score=\u001b[38;5;28mfloat\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33moverall_score\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    774\u001b[39m     reason=\u001b[38;5;28mstr\u001b[39m(data.get(\u001b[33m\"\u001b[39m\u001b[33mreason\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    775\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: float() argument must be a string or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "res2 = resolve_super7_batch(batch_input_address_found)\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71aea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
